{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_REVIEWER = \"\"\"\n",
    "# IDENTITY\n",
    "\n",
    "You are an AI named Codia. You have extensive knowledge and skill in programming languages, especially Python. You are aware of the best practices used in programming, have an extensive extensive experience in lagorithms, data structures and overall computer science.\n",
    "\n",
    "You are a concise expert in evaluating and refining the code generated by an AI assistant based on a Large Language Model.\n",
    "\n",
    "# GOALS\n",
    "\n",
    "Your task is to evaluate and provide feedback for a conversation between a human user and an AI Assistant that is based on the latest large language model architecture.\n",
    "Focus of your evaluation is code in the replies generated by the AI Assistant only. The conversation environment is a Jupyter notebook, thus things that are run in other cells, are available in the next cells.\n",
    "\n",
    "# RULES\n",
    "\n",
    "Attributes to consider:\n",
    "- Code Correctness\n",
    "- Code Efficiency\n",
    "- Best Practices\n",
    "- Code Readability\n",
    "- Code style Consistency\n",
    "- Code purpose and usefulness for user request satisfaction\n",
    "\n",
    "**1. Identification of Code for Review**\n",
    "- Target for analysis: Code generated by the LLM Assistant in a reply to the User within a Jupyter notebook exchange.\n",
    "- Exclude analysis of human user input for focused improvement on LLM-generated content.\n",
    "- Exclude LLM Assistant text content that is not related to the code, only review code snippets and code cells. Text is for context and reasoning/explanation only, you can assess meaning of the text in relation to the code.\n",
    "- Exclude concerns about code explanation in the text parts if they are not comments inside the code, as it will be covered by other reviewers.\n",
    "\n",
    "**2. Evaluation Criteria Definitions**\n",
    "- Correctness: The code must be devoid of bugs and errors.\n",
    "- Efficiency: The code must be optimized for maximum performance.\n",
    "- Best Practices: The code must adhere to established programming conventions, techniques, and guidelines.\n",
    "- Readability: The code must be easily comprehensible, with suitable naming conventions and comments where complexity demands.\n",
    "- Consistency: The code must be consistent with the Assistant's programming identity and the context of the user interaction.\n",
    "- Completeness of the conversation as a whole: was user request satisfied or does conversation still needs more interactions(very bad)?\n",
    "\n",
    "**3. Review Guidelines**\n",
    "- Avoid general praise observations: Be specific and objective in your feedback.\n",
    "- Avoid nitpicky/subjective criticism: Focus on substantial issues that affect the code quality.\n",
    "\n",
    "# OUTPUT_FORMAT\n",
    "\n",
    "Your output must be a JSON object with the following fields:\n",
    "\n",
    "# critical_severity_issues - list of issues that decrease usefulness of the Assistant code replies for the human user in major ways.\n",
    "# medium_severity_issues - list of issues that have a strong influence on the conversation flow and usefulness.\n",
    "# could_have_been_better_issues - list of issues that are suggestions that have almost no influence on the score\n",
    "Each issue should point out a specific problem and how to fix it in exec summary fashion. Start each issue with the cell position it was found in and a short piece of text to find specific place of the issue.\n",
    "Each issue consists of an `issue_dict` - should contain the following fields: `cell_position`, `what` is the issue, `why` it's an issue, `where` in the cell, how to `fix` it.\n",
    "\n",
    "# scoring_explanation - using rubrics, concisly point out the logic behind scoring this concersation.\n",
    "\n",
    "# score - a number between 1 and 5 that ranges from the quality of the code, where 1 is the worst and 5 is the best, based on the criteria outlined in the grading rubric.\n",
    "\n",
    "### 5 - Excellent\n",
    "- Well Formatted\n",
    "- Correct\n",
    "- Optimal\n",
    "- Highly readable\n",
    "- Useful\n",
    "- conversation must be complete ending in user request full satisfaction\n",
    "\n",
    "### 4 - Good\n",
    "- Correct but can be slightly optimized in terms of approach / speed / readability\n",
    "\n",
    "### 3 - Acceptable\n",
    "- The code is correct but can be significantly improved.\n",
    "- The code is not readable.\n",
    "\n",
    "### 2 - Needs Improvement\n",
    "- The code is incorrect / out of scope / has syntax errors.\n",
    "- Looks like itâ€™s copied from ChatGPT - robotic, no personality, inhuman.\n",
    "\n",
    "### 1 - Poor\n",
    "- Incomplete or missing Code, but is required or implied by context of the interaction to make it useful aka did not satisfy user's request and desire\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"critical_severity_issues\": list[issue_dict],\n",
    "    \"medium_severity_issues\": list[issue_dict],\n",
    "    \"could_have_been_better_issues\": list[issue_dict],\n",
    "    \"scoring_explanation\": str,\n",
    "    \"score\": number\n",
    "}\n",
    "```\n",
    "\n",
    "# REFOCUS:\n",
    "- You are a code reviewer, not a language and contextual information content reviewer. Do not mention issues not related to your purpose.\n",
    "- If the code was **unnecessary** aka user request FULLY satisfied without it, it can be absent and thus must receive null.\n",
    "- If code from assistant is necessary by the conversation flow to satisfy user's request but it is not there - score it as 1, do not mark as 5.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saya/chario/upstream_character_tasks/.venv/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "from src.llm_reviewer.llm_api import make_llm_request, LLMAPIFactory\n",
    "import os\n",
    "import sys\n",
    "from src.llm_reviewer.notebook_reviewer import IssueLevel\n",
    "from src.llm_reviewer.llm_api import global_usage_manager\n",
    "global_usage_manager.reset_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_review_request(nb):\n",
    "    llm_client = LLMAPIFactory().get()\n",
    "    cells_with_numbers = [{'cell_position': i + 1, **c,} for i, c in enumerate(nb['messages'])]\n",
    "    r = make_llm_request(\n",
    "        llm_client,\n",
    "        [{'role': 'system', 'content': CODE_REVIEWER}, {'role': 'user', 'content': f'# CONVERSATION_START\\n\\n\\n{cells_with_numbers}\\n\\n\\n# CONVERSATION_END'}],\n",
    "        'gpt-4-1106-preview',\n",
    "        temperature=0.0,\n",
    "        max_tokens=4000,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        retries=3,\n",
    "        seed=42\n",
    "    )\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def format_review_sections(data):\n",
    "    sections = [\"critical_severity_issues\", \"medium_severity_issues\", \"scoring_explanation\", \"score\"]\n",
    "    markdown_output = \"\"\n",
    "    for section in sections:\n",
    "        if section in data:\n",
    "            if isinstance(data[section], list):\n",
    "                markdown_output += f\"# {section.replace('_', ' ').title()}\\n\"\n",
    "                for issue in data[section]:\n",
    "                    issue_details = f\"**Cell {issue['cell_position']}**: {issue['what']}\\n\"\n",
    "                    issue_details += f\"- **Why**: {issue['why']}\\n\"\n",
    "                    issue_details += f\"- **Where**: {issue['where']}\\n\"\n",
    "                    issue_details += f\"- **Fix**: {issue['fix']}\\n\\n\"\n",
    "                    markdown_output += issue_details\n",
    "            else:\n",
    "                if section == \"score\":\n",
    "                    markdown_output += f\"# Score: {data[section]}\\n\\n\"\n",
    "                else:\n",
    "                    markdown_output += f\"# {section.replace('_', ' ').title()}\\n{data[section]}\\n\\n\"\n",
    "        else:\n",
    "            raise Exception(f'{section=} not found')\n",
    "    return markdown_output\n",
    "\n",
    "def print_as_markdown(data):\n",
    "    markdown_output = format_review_sections(data)\n",
    "    display(Markdown(markdown_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = make_review_request(notebook)\n",
    "print_as_markdown(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_revision_before_timestamp(file_id, timestamp):\n",
    "    try:\n",
    "        # Get the revisions of the file\n",
    "        revisions = drive_service.revisions().list(fileId=file_id).execute()\n",
    "    except Exception as e:\n",
    "        print(f\"File not found: {file_id}\")\n",
    "        return None\n",
    "\n",
    "    # Convert the timestamp to a datetime object\n",
    "    timestamp = pd.to_datetime(timestamp).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 12, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(\"12/20/2023 21:01:11\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m timezone\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming the string is already in GMT+2\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12/20/2023 21:01:11\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtz_localize(timezone(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEtc/GMT-2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m timestamp\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from pytz import timezone\n",
    "\n",
    "# Assuming the string is already in GMT+2\n",
    "timestamp = pd.to_datetime(\"12/20/2023 21:01:11\").tz_localize(timezone('Etc/GMT-2'))\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sheets_utils import download_sheet_as_df\n",
    "from utils import PROJECT_ROOT\n",
    "service_account_path = PROJECT_ROOT + \"creds/google__sa.json\"\n",
    "tracking_sheet_id = \"1qBU7Kvuuij2fxbqPxebReKMxWgIBmOIE5Gi4ZuX0j_4\"\n",
    "reviews_sheets_df = download_sheet_as_df(service_account_path, tracking_sheet_id, 'Reviews')\n",
    "from utils import get_delivered_df\n",
    "delivered_df = get_delivered_df([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "from src.gdrive_api.auth import build_service\n",
    "from datetime import timedelta\n",
    "\n",
    "utc_timezone = timezone.utc\n",
    "gmt_plus_2h_timezone = timezone(timedelta(hours=2))\n",
    "\n",
    "\n",
    "drive_service = build_service(service_account_path)\n",
    "def get_revision_before_timestamp(file_id, timestamp):\n",
    "    try:\n",
    "        # Get the revisions of the file\n",
    "        revisions = drive_service.revisions().list(fileId=file_id).execute()\n",
    "    except Exception as e:\n",
    "        print(f\"File not found: {file_id}\")\n",
    "        return None\n",
    "\n",
    "    # Convert the timestamp to a datetime object\n",
    "    \n",
    "    timestamp = pd.to_datetime(timestamp).tz_localize(gmt_plus_2h_timezone)\n",
    "\n",
    "    # Initialize the latest revision before the timestamp as None\n",
    "    latest_revision_before_timestamp = None\n",
    "\n",
    "    for revision in revisions['revisions']:\n",
    "        # Convert the modifiedTime of the revision to a datetime object\n",
    "        modified_time = pd.to_datetime(revision['modifiedTime'])\n",
    "        # If the modifiedTime is before the timestamp\n",
    "        if modified_time <= timestamp:\n",
    "            # If this is the first revision or this revision is later than the latest found so far\n",
    "            if latest_revision_before_timestamp is None or modified_time > pd.to_datetime(latest_revision_before_timestamp['modifiedTime']):\n",
    "                # Update the latest revision before the timestamp\n",
    "                latest_revision_before_timestamp = revision\n",
    "\n",
    "    return latest_revision_before_timestamp\n",
    "\n",
    "\n",
    "\n",
    "def get_file_id_from_task_link(task_link):\n",
    "    try:\n",
    "        return task_link.split(\"/\")[-1].split('#')[0]\n",
    "    except Exception as e:\n",
    "        print('ERROR' + '='*60)\n",
    "        print(task_link)\n",
    "        return None\n",
    "\n",
    "## Add a new column to the DataFrame for the file IDs\n",
    "#selected_rows_df['file_id'] = selected_rows_df['Task Link [Google Colab]'].apply(get_file_id_from_task_link)\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "#selected_rows_df['revision'] = selected_rows_df.apply(lambda row: get_revision_before_timestamp(row['file_id'], row['Timestamp']) if row['file_id'] is not None else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_revision_id_to_task_link(task_link, revision):\n",
    "    if revision is not None:\n",
    "        revision_id = revision.get('id')\n",
    "        return f\"{task_link}#revisionId={revision_id}\"\n",
    "    return task_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "selected_rows_df['task_link_rev'] = selected_rows_df.apply(lambda row: append_revision_id_to_task_link(row['Task Link [Google Colab]'], row['revision']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Task Link [Google Colab]</th>\n",
       "      <th>Code Quality</th>\n",
       "      <th>Language Quality</th>\n",
       "      <th>Feedback for the Trainer</th>\n",
       "      <th>Author Email</th>\n",
       "      <th>file_id</th>\n",
       "      <th>revision</th>\n",
       "      <th>task_link_rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/19/2023 12:01:41</td>\n",
       "      <td>youssef.h@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1ZSjvo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The header of the code cell should be \"# Assis...</td>\n",
       "      <td>None</td>\n",
       "      <td>1ZSjvocSfnuFQY-8gGSggGUEtfnLfS_B4</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcalFrU1l4ZHppYlVtUnQ2VFptN...</td>\n",
       "      <td>https://colab.research.google.com/drive/1ZSjvo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/19/2023 12:09:35</td>\n",
       "      <td>youssef.h@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1nv28F...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>++The code is correct, concise and well struct...</td>\n",
       "      <td>None</td>\n",
       "      <td>1nv28F9bJOHxEXJUaLQv3V9z8Fj8SHzmV</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcdlFMRFF6YkcxNDhzZzlOUDhsa...</td>\n",
       "      <td>https://colab.research.google.com/drive/1nv28F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/19/2023 12:31:33</td>\n",
       "      <td>youssef.h@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1nBjh1...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>++ Code is clean and well structured\\n++Langua...</td>\n",
       "      <td>None</td>\n",
       "      <td>1nBjh1lLJuZX9kIIdVaHQPrHnWF4tx7Sg</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcN1JSYXVuOTl2U0M1T1N0ZWgrc...</td>\n",
       "      <td>https://colab.research.google.com/drive/1nBjh1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>12/23/2023 14:38:04</td>\n",
       "      <td>youssef.h@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/17eg2v...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>This looks good.\\n\\nThe code could be improved...</td>\n",
       "      <td>caram.v@turing.com</td>\n",
       "      <td>17eg2v1KiqRXymrzVdky6sni_jesoQzAu</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcc1VkZXVuNGRrcStDbVpzMC81V...</td>\n",
       "      <td>https://colab.research.google.com/drive/17eg2v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>12/23/2023 14:40:57</td>\n",
       "      <td>youssef.h@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1XOkKN...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Good!</td>\n",
       "      <td>caram.v@turing.com</td>\n",
       "      <td>1XOkKNQnu93JN5bIFAMe6W-8NdfF5Qo0-</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcTGxHZll5aERGdmJhbkxhQThGV...</td>\n",
       "      <td>https://colab.research.google.com/drive/1XOkKN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>12/23/2023 14:47:27</td>\n",
       "      <td>youssef.h@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1VmX6t...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>--The first assistant markdown has multiple gr...</td>\n",
       "      <td>rohit.kumar@turing.com</td>\n",
       "      <td>1VmX6t6BuosB-HooXaYOgMgW0_uuzZ42z</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcZUJmZXJCcnhUT0UyQzhnaDBta...</td>\n",
       "      <td>https://colab.research.google.com/drive/1VmX6t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>12/23/2023 14:56:30</td>\n",
       "      <td>youssef.h@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1CQSKk...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>--Conversation does not meet the minimum lengt...</td>\n",
       "      <td>rohit.kumar@turing.com</td>\n",
       "      <td>1CQSKk-8ceLdmyBUKHT16aM2unS4U5Tgu</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcQVpIZGl3Zzh4V1BCenU2dkhtW...</td>\n",
       "      <td>https://colab.research.google.com/drive/1CQSKk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12/20/2023 19:38:33</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/11CEko...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>++ Code is clean and well structured \\n++ Test...</td>\n",
       "      <td>hriday.thakkar@turing.com</td>\n",
       "      <td>11CEkoZ0S3dbU1-2Cp5b1YTZf0HkI8ljV</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcMGhnQkFyZVB3MnhiOWxvM1Ixd...</td>\n",
       "      <td>https://colab.research.google.com/drive/11CEko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12/20/2023 19:55:29</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1dsE7l...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-- Incorrect use of f-string in the last print...</td>\n",
       "      <td>ali.nauman@turing.com</td>\n",
       "      <td>1dsE7ljA8jt4lvYHdc60Kdtme2Y829m41</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcekVjUFF3UTlrOEtEVkVNc1VCU...</td>\n",
       "      <td>https://colab.research.google.com/drive/1dsE7l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12/20/2023 19:57:38</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1wEgUF...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>++ code is clean and well structured\\n++ comme...</td>\n",
       "      <td>riya.dhar@turing.com</td>\n",
       "      <td>1wEgUF08nHpAhTSvWaDR8uPnrDzw1PnEm</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhccWYyYzFnRzhpRGtWY3B0VXBmW...</td>\n",
       "      <td>https://colab.research.google.com/drive/1wEgUF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12/20/2023 20:32:34</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/15AXjZ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-- Would be better if you added few more inlin...</td>\n",
       "      <td>ali.nauman@turing.com</td>\n",
       "      <td>15AXjZoIhlO9GZl9BTKxSh9JHJkIl_Qh2</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcTWtnTHEwQ2V4L1h2a1lnZU5yT...</td>\n",
       "      <td>https://colab.research.google.com/drive/15AXjZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12/20/2023 20:33:07</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/15e4n1...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-- Code is too long and verbose. (Demo a singl...</td>\n",
       "      <td>navaneethan.ramasamy@turing.com</td>\n",
       "      <td>15e4n1X2I_mqvRwlOjq7hPifzm2azgEL2</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcYjNnVm55c0RvMFE3OXJZM1Zja...</td>\n",
       "      <td>https://colab.research.google.com/drive/15e4n1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12/20/2023 20:26:01</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/12nfkD...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-- Stick to what is asked by the user, the use...</td>\n",
       "      <td>hafiz.t@turing.com</td>\n",
       "      <td>12nfkDX-2gp_0wNbDZr_MUbYYq3RI_cgQ</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcQTcvUzNmTVlPM3VZbldUeGk3Q...</td>\n",
       "      <td>https://colab.research.google.com/drive/12nfkD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12/20/2023 20:46:19</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1wAM4c...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-- Add (# Assistant) header in the code block ...</td>\n",
       "      <td>yuzhao.ni@turing.com</td>\n",
       "      <td>1wAM4cF6ffCHAzthXoiBGgTtM4D11VBTa</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcY3NBd1FQTVNtTk5STDhIMnc0c...</td>\n",
       "      <td>https://colab.research.google.com/drive/1wAM4c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12/20/2023 20:49:40</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1Eopvh...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>++ everything looks good</td>\n",
       "      <td>daniel.oluwakayode-c@turing.com</td>\n",
       "      <td>1EopvhvJY5jIJ-klDdoNK5r2LCXngqQSo</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcSExkTUdPRm5PU1NjK3JVck9TK...</td>\n",
       "      <td>https://colab.research.google.com/drive/1Eopvh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12/20/2023 21:01:11</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1OsBof...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-- Add (# Assistant) Header in your code block...</td>\n",
       "      <td>james.oladimeji-c@turing.com</td>\n",
       "      <td>1OsBofqnxG2Kisd1n1LmQpdLxSw2qh0h8</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcRzFJV1JPQTRGWGUwcEJjYnViS...</td>\n",
       "      <td>https://colab.research.google.com/drive/1OsBof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12/21/2023 9:39:33</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1MYtCR...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-- a more pythonic way to do this is using f-s...</td>\n",
       "      <td>muthahhari.p@turing.com</td>\n",
       "      <td>1MYtCRrpLnPvpnV3V1X_c51v9I1tt8kiw</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcb2Jxb2JDVFVsNzdhR1JaOUxBa...</td>\n",
       "      <td>https://colab.research.google.com/drive/1MYtCR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12/21/2023 9:44:07</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/14AhL8...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-- explanation is not clear\\n-- use backtick (...</td>\n",
       "      <td>basit.n@turing.com</td>\n",
       "      <td>14AhL8HWAXECEMpZYi1ih4egEHztreXBt</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcZVJPU3BQWUhwN1E1QWtPTHllW...</td>\n",
       "      <td>https://colab.research.google.com/drive/14AhL8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12/21/2023 9:51:04</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/17qaUh...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-- add bit more explanation (either inline com...</td>\n",
       "      <td>adamjee.m@turing.com</td>\n",
       "      <td>17qaUhO3VmOkVJiRx_JSEDspVsqRZyCne</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcRGdVU3p5TWtpeTVsYXJvd3hjb...</td>\n",
       "      <td>https://colab.research.google.com/drive/17qaUh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12/21/2023 9:57:53</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1jsED2...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-- use context manager to deal with files\\n-- ...</td>\n",
       "      <td>basani.a@turing.com</td>\n",
       "      <td>1jsED2F__k8qamKqxpnydyalGvHXW8fWT</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcMGxHUVJDTjJDV2pkVTUvOStJN...</td>\n",
       "      <td>https://colab.research.google.com/drive/1jsED2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12/21/2023 10:00:21</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/13Rb92...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>++ code is clean and readable with suitable in...</td>\n",
       "      <td>toh.y@turing.com</td>\n",
       "      <td>13Rb927-8UjXiAmR69M-hCogWVdmAe3Xo</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcR2lmVXFOMXVMa1F3YWFuSkpZQ...</td>\n",
       "      <td>https://colab.research.google.com/drive/13Rb92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12/21/2023 11:46:47</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1b6RV7...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-- re-check your code , the output seems wrong...</td>\n",
       "      <td>shaharyar.t@turing.com</td>\n",
       "      <td>1b6RV7cnOXF65gnuic9isZdAZTcGd_l-z</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhccXY3dWhDWW15TkhwaFhkWkpRS...</td>\n",
       "      <td>https://colab.research.google.com/drive/1b6RV7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12/21/2023 11:53:15</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1BHcRv...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>++ Looks good \\nSuggestion : Add inline commen...</td>\n",
       "      <td>toh.y@turing.com</td>\n",
       "      <td>1BHcRvU1AtFmTYZW7-NnKYUQdn9G27PBv</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcN1JBYjRkMHhoeSthb1pIK0JoU...</td>\n",
       "      <td>https://colab.research.google.com/drive/1BHcRv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12/21/2023 11:58:14</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1bivSL...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>++ well structured code with appropriate inlin...</td>\n",
       "      <td>muhammad.o@turing.com</td>\n",
       "      <td>1bivSLCOxOOoOcIRYq7y-zqEccCGIgi2z</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcdzB0SnRoMXRlaTFaclVLWUNnM...</td>\n",
       "      <td>https://colab.research.google.com/drive/1bivSL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12/21/2023 12:02:17</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1bNGIo...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>++ code and explanation are good \\n-- there is...</td>\n",
       "      <td>icaro.c@turing.com</td>\n",
       "      <td>1bNGIozJ8uQhvIjbhppZYZMOqgNB87XVZ</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcQU5ZUjFxSXpxT0lIY0d6MmM0T...</td>\n",
       "      <td>https://colab.research.google.com/drive/1bNGIo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12/21/2023 12:06:43</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1efYx0...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>++ code and explanations are good \\nSuggestion...</td>\n",
       "      <td>edwin.n@turing.com</td>\n",
       "      <td>1efYx0Z-MgXzJ8K1zGdIPWkwlIlG6RqL7</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcUnB6eEdwa3pVZ0xGc3JMbzNqb...</td>\n",
       "      <td>https://colab.research.google.com/drive/1efYx0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12/21/2023 13:16:59</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1epNcE...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-- inadequate explanation. (Add (short)a gener...</td>\n",
       "      <td>ritesh.r@turing.com</td>\n",
       "      <td>1epNcEzrW30VtucMS4A66I1mHYW3r-leS</td>\n",
       "      <td>{'id': '0BxmKQQ91GHhcQS8vSHNnUzgvcXpJSW91SjVua...</td>\n",
       "      <td>https://colab.research.google.com/drive/1epNcE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Timestamp             Email Address  \\\n",
       "1   12/19/2023 12:01:41      youssef.h@turing.com   \n",
       "2   12/19/2023 12:09:35      youssef.h@turing.com   \n",
       "3   12/19/2023 12:31:33      youssef.h@turing.com   \n",
       "58  12/23/2023 14:38:04      youssef.h@turing.com   \n",
       "59  12/23/2023 14:40:57      youssef.h@turing.com   \n",
       "60  12/23/2023 14:47:27      youssef.h@turing.com   \n",
       "61  12/23/2023 14:56:30      youssef.h@turing.com   \n",
       "8   12/20/2023 19:38:33  chirag.rade-c@turing.com   \n",
       "9   12/20/2023 19:55:29  chirag.rade-c@turing.com   \n",
       "10  12/20/2023 19:57:38  chirag.rade-c@turing.com   \n",
       "11  12/20/2023 20:32:34  chirag.rade-c@turing.com   \n",
       "12  12/20/2023 20:33:07  chirag.rade-c@turing.com   \n",
       "13  12/20/2023 20:26:01  chirag.rade-c@turing.com   \n",
       "14  12/20/2023 20:46:19  chirag.rade-c@turing.com   \n",
       "15  12/20/2023 20:49:40  chirag.rade-c@turing.com   \n",
       "16  12/20/2023 21:01:11  chirag.rade-c@turing.com   \n",
       "17   12/21/2023 9:39:33  chirag.rade-c@turing.com   \n",
       "18   12/21/2023 9:44:07  chirag.rade-c@turing.com   \n",
       "19   12/21/2023 9:51:04  chirag.rade-c@turing.com   \n",
       "20   12/21/2023 9:57:53  chirag.rade-c@turing.com   \n",
       "21  12/21/2023 10:00:21  chirag.rade-c@turing.com   \n",
       "22  12/21/2023 11:46:47  chirag.rade-c@turing.com   \n",
       "23  12/21/2023 11:53:15  chirag.rade-c@turing.com   \n",
       "24  12/21/2023 11:58:14  chirag.rade-c@turing.com   \n",
       "25  12/21/2023 12:02:17  chirag.rade-c@turing.com   \n",
       "26  12/21/2023 12:06:43  chirag.rade-c@turing.com   \n",
       "27  12/21/2023 13:16:59  chirag.rade-c@turing.com   \n",
       "\n",
       "                             Task Link [Google Colab] Code Quality  \\\n",
       "1   https://colab.research.google.com/drive/1ZSjvo...            4   \n",
       "2   https://colab.research.google.com/drive/1nv28F...            5   \n",
       "3   https://colab.research.google.com/drive/1nBjh1...            4   \n",
       "58  https://colab.research.google.com/drive/17eg2v...            4   \n",
       "59  https://colab.research.google.com/drive/1XOkKN...            5   \n",
       "60  https://colab.research.google.com/drive/1VmX6t...            5   \n",
       "61  https://colab.research.google.com/drive/1CQSKk...            3   \n",
       "8   https://colab.research.google.com/drive/11CEko...            5   \n",
       "9   https://colab.research.google.com/drive/1dsE7l...            3   \n",
       "10  https://colab.research.google.com/drive/1wEgUF...            5   \n",
       "11  https://colab.research.google.com/drive/15AXjZ...            4   \n",
       "12  https://colab.research.google.com/drive/15e4n1...            3   \n",
       "13  https://colab.research.google.com/drive/12nfkD...            3   \n",
       "14  https://colab.research.google.com/drive/1wAM4c...            4   \n",
       "15  https://colab.research.google.com/drive/1Eopvh...            5   \n",
       "16  https://colab.research.google.com/drive/1OsBof...            4   \n",
       "17  https://colab.research.google.com/drive/1MYtCR...            3   \n",
       "18  https://colab.research.google.com/drive/14AhL8...            4   \n",
       "19  https://colab.research.google.com/drive/17qaUh...            4   \n",
       "20  https://colab.research.google.com/drive/1jsED2...            3   \n",
       "21  https://colab.research.google.com/drive/13Rb92...            5   \n",
       "22  https://colab.research.google.com/drive/1b6RV7...            2   \n",
       "23  https://colab.research.google.com/drive/1BHcRv...            5   \n",
       "24  https://colab.research.google.com/drive/1bivSL...            5   \n",
       "25  https://colab.research.google.com/drive/1bNGIo...            4   \n",
       "26  https://colab.research.google.com/drive/1efYx0...            5   \n",
       "27  https://colab.research.google.com/drive/1epNcE...            3   \n",
       "\n",
       "   Language Quality                           Feedback for the Trainer  \\\n",
       "1                 4  The header of the code cell should be \"# Assis...   \n",
       "2                 3  ++The code is correct, concise and well struct...   \n",
       "3                 5  ++ Code is clean and well structured\\n++Langua...   \n",
       "58                5  This looks good.\\n\\nThe code could be improved...   \n",
       "59                5                                         Very Good!   \n",
       "60                3  --The first assistant markdown has multiple gr...   \n",
       "61                3  --Conversation does not meet the minimum lengt...   \n",
       "8                 4  ++ Code is clean and well structured \\n++ Test...   \n",
       "9                 4  -- Incorrect use of f-string in the last print...   \n",
       "10                4  ++ code is clean and well structured\\n++ comme...   \n",
       "11                3  -- Would be better if you added few more inlin...   \n",
       "12                3  -- Code is too long and verbose. (Demo a singl...   \n",
       "13                4  -- Stick to what is asked by the user, the use...   \n",
       "14                3  -- Add (# Assistant) header in the code block ...   \n",
       "15                5                           ++ everything looks good   \n",
       "16                4  -- Add (# Assistant) Header in your code block...   \n",
       "17                4  -- a more pythonic way to do this is using f-s...   \n",
       "18                3  -- explanation is not clear\\n-- use backtick (...   \n",
       "19                4  -- add bit more explanation (either inline com...   \n",
       "20                3  -- use context manager to deal with files\\n-- ...   \n",
       "21                3  ++ code is clean and readable with suitable in...   \n",
       "22                3  -- re-check your code , the output seems wrong...   \n",
       "23                5  ++ Looks good \\nSuggestion : Add inline commen...   \n",
       "24                4  ++ well structured code with appropriate inlin...   \n",
       "25                5  ++ code and explanation are good \\n-- there is...   \n",
       "26                5  ++ code and explanations are good \\nSuggestion...   \n",
       "27                3  -- inadequate explanation. (Add (short)a gener...   \n",
       "\n",
       "                       Author Email                            file_id  \\\n",
       "1                              None  1ZSjvocSfnuFQY-8gGSggGUEtfnLfS_B4   \n",
       "2                              None  1nv28F9bJOHxEXJUaLQv3V9z8Fj8SHzmV   \n",
       "3                              None  1nBjh1lLJuZX9kIIdVaHQPrHnWF4tx7Sg   \n",
       "58               caram.v@turing.com  17eg2v1KiqRXymrzVdky6sni_jesoQzAu   \n",
       "59               caram.v@turing.com  1XOkKNQnu93JN5bIFAMe6W-8NdfF5Qo0-   \n",
       "60           rohit.kumar@turing.com  1VmX6t6BuosB-HooXaYOgMgW0_uuzZ42z   \n",
       "61           rohit.kumar@turing.com  1CQSKk-8ceLdmyBUKHT16aM2unS4U5Tgu   \n",
       "8         hriday.thakkar@turing.com  11CEkoZ0S3dbU1-2Cp5b1YTZf0HkI8ljV   \n",
       "9             ali.nauman@turing.com  1dsE7ljA8jt4lvYHdc60Kdtme2Y829m41   \n",
       "10             riya.dhar@turing.com  1wEgUF08nHpAhTSvWaDR8uPnrDzw1PnEm   \n",
       "11            ali.nauman@turing.com  15AXjZoIhlO9GZl9BTKxSh9JHJkIl_Qh2   \n",
       "12  navaneethan.ramasamy@turing.com  15e4n1X2I_mqvRwlOjq7hPifzm2azgEL2   \n",
       "13               hafiz.t@turing.com  12nfkDX-2gp_0wNbDZr_MUbYYq3RI_cgQ   \n",
       "14             yuzhao.ni@turing.com  1wAM4cF6ffCHAzthXoiBGgTtM4D11VBTa   \n",
       "15  daniel.oluwakayode-c@turing.com  1EopvhvJY5jIJ-klDdoNK5r2LCXngqQSo   \n",
       "16     james.oladimeji-c@turing.com  1OsBofqnxG2Kisd1n1LmQpdLxSw2qh0h8   \n",
       "17          muthahhari.p@turing.com  1MYtCRrpLnPvpnV3V1X_c51v9I1tt8kiw   \n",
       "18               basit.n@turing.com  14AhL8HWAXECEMpZYi1ih4egEHztreXBt   \n",
       "19             adamjee.m@turing.com  17qaUhO3VmOkVJiRx_JSEDspVsqRZyCne   \n",
       "20              basani.a@turing.com  1jsED2F__k8qamKqxpnydyalGvHXW8fWT   \n",
       "21                 toh.y@turing.com  13Rb927-8UjXiAmR69M-hCogWVdmAe3Xo   \n",
       "22           shaharyar.t@turing.com  1b6RV7cnOXF65gnuic9isZdAZTcGd_l-z   \n",
       "23                 toh.y@turing.com  1BHcRvU1AtFmTYZW7-NnKYUQdn9G27PBv   \n",
       "24            muhammad.o@turing.com  1bivSLCOxOOoOcIRYq7y-zqEccCGIgi2z   \n",
       "25               icaro.c@turing.com  1bNGIozJ8uQhvIjbhppZYZMOqgNB87XVZ   \n",
       "26               edwin.n@turing.com  1efYx0Z-MgXzJ8K1zGdIPWkwlIlG6RqL7   \n",
       "27              ritesh.r@turing.com  1epNcEzrW30VtucMS4A66I1mHYW3r-leS   \n",
       "\n",
       "                                             revision  \\\n",
       "1   {'id': '0BxmKQQ91GHhcalFrU1l4ZHppYlVtUnQ2VFptN...   \n",
       "2   {'id': '0BxmKQQ91GHhcdlFMRFF6YkcxNDhzZzlOUDhsa...   \n",
       "3   {'id': '0BxmKQQ91GHhcN1JSYXVuOTl2U0M1T1N0ZWgrc...   \n",
       "58  {'id': '0BxmKQQ91GHhcc1VkZXVuNGRrcStDbVpzMC81V...   \n",
       "59  {'id': '0BxmKQQ91GHhcTGxHZll5aERGdmJhbkxhQThGV...   \n",
       "60  {'id': '0BxmKQQ91GHhcZUJmZXJCcnhUT0UyQzhnaDBta...   \n",
       "61  {'id': '0BxmKQQ91GHhcQVpIZGl3Zzh4V1BCenU2dkhtW...   \n",
       "8   {'id': '0BxmKQQ91GHhcMGhnQkFyZVB3MnhiOWxvM1Ixd...   \n",
       "9   {'id': '0BxmKQQ91GHhcekVjUFF3UTlrOEtEVkVNc1VCU...   \n",
       "10  {'id': '0BxmKQQ91GHhccWYyYzFnRzhpRGtWY3B0VXBmW...   \n",
       "11  {'id': '0BxmKQQ91GHhcTWtnTHEwQ2V4L1h2a1lnZU5yT...   \n",
       "12  {'id': '0BxmKQQ91GHhcYjNnVm55c0RvMFE3OXJZM1Zja...   \n",
       "13  {'id': '0BxmKQQ91GHhcQTcvUzNmTVlPM3VZbldUeGk3Q...   \n",
       "14  {'id': '0BxmKQQ91GHhcY3NBd1FQTVNtTk5STDhIMnc0c...   \n",
       "15  {'id': '0BxmKQQ91GHhcSExkTUdPRm5PU1NjK3JVck9TK...   \n",
       "16  {'id': '0BxmKQQ91GHhcRzFJV1JPQTRGWGUwcEJjYnViS...   \n",
       "17  {'id': '0BxmKQQ91GHhcb2Jxb2JDVFVsNzdhR1JaOUxBa...   \n",
       "18  {'id': '0BxmKQQ91GHhcZVJPU3BQWUhwN1E1QWtPTHllW...   \n",
       "19  {'id': '0BxmKQQ91GHhcRGdVU3p5TWtpeTVsYXJvd3hjb...   \n",
       "20  {'id': '0BxmKQQ91GHhcMGxHUVJDTjJDV2pkVTUvOStJN...   \n",
       "21  {'id': '0BxmKQQ91GHhcR2lmVXFOMXVMa1F3YWFuSkpZQ...   \n",
       "22  {'id': '0BxmKQQ91GHhccXY3dWhDWW15TkhwaFhkWkpRS...   \n",
       "23  {'id': '0BxmKQQ91GHhcN1JBYjRkMHhoeSthb1pIK0JoU...   \n",
       "24  {'id': '0BxmKQQ91GHhcdzB0SnRoMXRlaTFaclVLWUNnM...   \n",
       "25  {'id': '0BxmKQQ91GHhcQU5ZUjFxSXpxT0lIY0d6MmM0T...   \n",
       "26  {'id': '0BxmKQQ91GHhcUnB6eEdwa3pVZ0xGc3JMbzNqb...   \n",
       "27  {'id': '0BxmKQQ91GHhcQS8vSHNnUzgvcXpJSW91SjVua...   \n",
       "\n",
       "                                        task_link_rev  \n",
       "1   https://colab.research.google.com/drive/1ZSjvo...  \n",
       "2   https://colab.research.google.com/drive/1nv28F...  \n",
       "3   https://colab.research.google.com/drive/1nBjh1...  \n",
       "58  https://colab.research.google.com/drive/17eg2v...  \n",
       "59  https://colab.research.google.com/drive/1XOkKN...  \n",
       "60  https://colab.research.google.com/drive/1VmX6t...  \n",
       "61  https://colab.research.google.com/drive/1CQSKk...  \n",
       "8   https://colab.research.google.com/drive/11CEko...  \n",
       "9   https://colab.research.google.com/drive/1dsE7l...  \n",
       "10  https://colab.research.google.com/drive/1wEgUF...  \n",
       "11  https://colab.research.google.com/drive/15AXjZ...  \n",
       "12  https://colab.research.google.com/drive/15e4n1...  \n",
       "13  https://colab.research.google.com/drive/12nfkD...  \n",
       "14  https://colab.research.google.com/drive/1wAM4c...  \n",
       "15  https://colab.research.google.com/drive/1Eopvh...  \n",
       "16  https://colab.research.google.com/drive/1OsBof...  \n",
       "17  https://colab.research.google.com/drive/1MYtCR...  \n",
       "18  https://colab.research.google.com/drive/14AhL8...  \n",
       "19  https://colab.research.google.com/drive/17qaUh...  \n",
       "20  https://colab.research.google.com/drive/1jsED2...  \n",
       "21  https://colab.research.google.com/drive/13Rb92...  \n",
       "22  https://colab.research.google.com/drive/1b6RV7...  \n",
       "23  https://colab.research.google.com/drive/1BHcRv...  \n",
       "24  https://colab.research.google.com/drive/1bivSL...  \n",
       "25  https://colab.research.google.com/drive/1bNGIo...  \n",
       "26  https://colab.research.google.com/drive/1efYx0...  \n",
       "27  https://colab.research.google.com/drive/1epNcE...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import utils\n",
    "from importlib import reload\n",
    "import jsonl_dump\n",
    "reload(jsonl_dump)\n",
    "from jsonl_dump import download_and_parse_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and parsing notebook 2/27 (File ID: 1ZSjvocSfnuFQY-8gGSggGUEtfnLfS_B4, Revision ID: 0BxmKQQ91GHhcalFrU1l4ZHppYlVtUnQ2VFptNTAzVUpGNnhNPQ)\n",
      "Download progress: 100%.\n",
      "Filling out missing header...\n",
      "Downloading and parsing notebook 3/27 (File ID: 1nv28F9bJOHxEXJUaLQv3V9z8Fj8SHzmV, Revision ID: 0BxmKQQ91GHhcdlFMRFF6YkcxNDhzZzlOUDhsaFRISjNzSndvPQ)\n",
      "Download progress: 100%.\n",
      "Filling out missing header...\n",
      "Downloading and parsing notebook 4/27 (File ID: 1nBjh1lLJuZX9kIIdVaHQPrHnWF4tx7Sg, Revision ID: 0BxmKQQ91GHhcN1JSYXVuOTl2U0M1T1N0ZWgrcjNCYlhOTkVVPQ)\n",
      "Download progress: 100%.\n",
      "Filling out missing header...\n",
      "Downloading and parsing notebook 59/27 (File ID: 17eg2v1KiqRXymrzVdky6sni_jesoQzAu, Revision ID: 0BxmKQQ91GHhcc1VkZXVuNGRrcStDbVpzMC81VGFKY1RJRTl3PQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 60/27 (File ID: 1XOkKNQnu93JN5bIFAMe6W-8NdfF5Qo0-, Revision ID: 0BxmKQQ91GHhcTGxHZll5aERGdmJhbkxhQThGVFpwV2VHa0VnPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 61/27 (File ID: 1VmX6t6BuosB-HooXaYOgMgW0_uuzZ42z, Revision ID: 0BxmKQQ91GHhcZUJmZXJCcnhUT0UyQzhnaDBtaTZSeUhGMUFvPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 62/27 (File ID: 1CQSKk-8ceLdmyBUKHT16aM2unS4U5Tgu, Revision ID: 0BxmKQQ91GHhcQVpIZGl3Zzh4V1BCenU2dkhtWVNzN1ZJQW5VPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 9/27 (File ID: 11CEkoZ0S3dbU1-2Cp5b1YTZf0HkI8ljV, Revision ID: 0BxmKQQ91GHhcMGhnQkFyZVB3MnhiOWxvM1Ixd3ZmeEpza1lRPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 10/27 (File ID: 1dsE7ljA8jt4lvYHdc60Kdtme2Y829m41, Revision ID: 0BxmKQQ91GHhcekVjUFF3UTlrOEtEVkVNc1VCUlJsUW5mc2Y4PQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 11/27 (File ID: 1wEgUF08nHpAhTSvWaDR8uPnrDzw1PnEm, Revision ID: 0BxmKQQ91GHhccWYyYzFnRzhpRGtWY3B0VXBmWXVuMXdlM0d3PQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 12/27 (File ID: 15AXjZoIhlO9GZl9BTKxSh9JHJkIl_Qh2, Revision ID: 0BxmKQQ91GHhcTWtnTHEwQ2V4L1h2a1lnZU5yT3JWVGp5NW9jPQ)\n",
      "Download progress: 100%.\n",
      "Filling out missing header...\n",
      "Downloading and parsing notebook 13/27 (File ID: 15e4n1X2I_mqvRwlOjq7hPifzm2azgEL2, Revision ID: 0BxmKQQ91GHhcYjNnVm55c0RvMFE3OXJZM1ZjaWhYa3YwaGRjPQ)\n",
      "Download progress: 100%.\n",
      "Filling out missing header...\n",
      "Downloading and parsing notebook 14/27 (File ID: 12nfkDX-2gp_0wNbDZr_MUbYYq3RI_cgQ, Revision ID: 0BxmKQQ91GHhcQTcvUzNmTVlPM3VZbldUeGk3Q3ZaTFMzcWt3PQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 15/27 (File ID: 1wAM4cF6ffCHAzthXoiBGgTtM4D11VBTa, Revision ID: 0BxmKQQ91GHhcY3NBd1FQTVNtTk5STDhIMnc0cWYzaDdjRGUwPQ)\n",
      "Download progress: 100%.\n",
      "Filling out missing header...\n",
      "Downloading and parsing notebook 16/27 (File ID: 1EopvhvJY5jIJ-klDdoNK5r2LCXngqQSo, Revision ID: 0BxmKQQ91GHhcSExkTUdPRm5PU1NjK3JVck9TKzlINTJ3bjk0PQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 17/27 (File ID: 1OsBofqnxG2Kisd1n1LmQpdLxSw2qh0h8, Revision ID: 0BxmKQQ91GHhcRzFJV1JPQTRGWGUwcEJjYnViSkZyM2JPOGFFPQ)\n",
      "Download progress: 100%.\n",
      "Filling out missing header...\n",
      "Downloading and parsing notebook 18/27 (File ID: 1MYtCRrpLnPvpnV3V1X_c51v9I1tt8kiw, Revision ID: 0BxmKQQ91GHhcb2Jxb2JDVFVsNzdhR1JaOUxBa2pLVWdxN1hNPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 19/27 (File ID: 14AhL8HWAXECEMpZYi1ih4egEHztreXBt, Revision ID: 0BxmKQQ91GHhcZVJPU3BQWUhwN1E1QWtPTHllWnNpeVgrbVJZPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 20/27 (File ID: 17qaUhO3VmOkVJiRx_JSEDspVsqRZyCne, Revision ID: 0BxmKQQ91GHhcRGdVU3p5TWtpeTVsYXJvd3hjbFNoem5KK0M0PQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 21/27 (File ID: 1jsED2F__k8qamKqxpnydyalGvHXW8fWT, Revision ID: 0BxmKQQ91GHhcMGxHUVJDTjJDV2pkVTUvOStJNU5KQzQzZ05JPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 22/27 (File ID: 13Rb927-8UjXiAmR69M-hCogWVdmAe3Xo, Revision ID: 0BxmKQQ91GHhcR2lmVXFOMXVMa1F3YWFuSkpZQTYyZGhpNllvPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 23/27 (File ID: 1b6RV7cnOXF65gnuic9isZdAZTcGd_l-z, Revision ID: 0BxmKQQ91GHhccXY3dWhDWW15TkhwaFhkWkpRSldxRTFkUlFRPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 24/27 (File ID: 1BHcRvU1AtFmTYZW7-NnKYUQdn9G27PBv, Revision ID: 0BxmKQQ91GHhcN1JBYjRkMHhoeSthb1pIK0JoUnZkSEVTUlI4PQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 25/27 (File ID: 1bivSLCOxOOoOcIRYq7y-zqEccCGIgi2z, Revision ID: 0BxmKQQ91GHhcdzB0SnRoMXRlaTFaclVLWUNnMXZWbTR0dXhJPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 26/27 (File ID: 1bNGIozJ8uQhvIjbhppZYZMOqgNB87XVZ, Revision ID: 0BxmKQQ91GHhcQU5ZUjFxSXpxT0lIY0d6MmM0TjQzdHdYd05nPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 27/27 (File ID: 1efYx0Z-MgXzJ8K1zGdIPWkwlIlG6RqL7, Revision ID: 0BxmKQQ91GHhcUnB6eEdwa3pVZ0xGc3JMbzNqbFJzbExocG00PQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 28/27 (File ID: 1epNcEzrW30VtucMS4A66I1mHYW3r-leS, Revision ID: 0BxmKQQ91GHhcQS8vSHNnUzgvcXpJSW91SjVuaVdHYXBqck8wPQ)\n",
      "Download progress: 100%.\n",
      "Filling out missing header...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parsed_notebooks = []\n",
    "for i, (index, row) in enumerate(selected_rows_df.iterrows()):\n",
    "    file_id = row['file_id']\n",
    "    revision_id = row['revision'].get('id') if row['revision'] is not None else None\n",
    "    print(f\"Downloading and parsing notebook {i+1}/{len(selected_rows_df)} (File ID: {file_id}, Revision ID: {revision_id})\")\n",
    "    parsed_notebook = download_and_parse_notebook(service_account_path, file_id, revision_id)\n",
    "    parsed_notebooks.append(parsed_notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'User',\n",
       "  'content': \"What's the Python code for a segment tree to handle range queries and updates?\",\n",
       "  'type': 'markdown'},\n",
       " {'role': 'Assistant',\n",
       "  'content': 'Here is a `SegmentTree` class with methods to build the tree, update a value, and query a range sum.',\n",
       "  'type': 'markdown'},\n",
       " {'role': 'Assistant',\n",
       "  'content': '# LLM\\n\\nclass SegmentTree:\\n    def __init__(self, nums):\\n        self.n = len(nums)\\n        self.tree = [0] * (4 * self.n)\\n        self.build_tree(nums, 0, 0, self.n - 1)\\n\\n    def build_tree(self, nums, tree_index, lo, hi):\\n        if lo == hi:\\n            self.tree[tree_index] = nums[lo]\\n            return\\n        mid = (lo + hi) // 2\\n        left_child = 2 * tree_index + 1\\n        right_child = 2 * tree_index + 2\\n        self.build_tree(nums, left_child, lo, mid)\\n        self.build_tree(nums, right_child, mid + 1, hi)\\n        self.tree[tree_index] = self.tree[left_child] + self.tree[right_child]\\n\\n    def update(self, index, val):\\n        def update_recursive(tree_index, lo, hi):\\n            if lo == hi:\\n                self.tree[tree_index] = val\\n                return\\n            mid = (lo + hi) // 2\\n            left_child = 2 * tree_index + 1\\n            right_child = 2 * tree_index + 2\\n            if index <= mid:\\n                update_recursive(left_child, lo, mid)\\n            else:\\n                update_recursive(right_child, mid + 1, hi)\\n            self.tree[tree_index] = self.tree[left_child] + self.tree[right_child]\\n\\n        update_recursive(0, 0, self.n - 1)\\n\\n    def query(self, i, j):\\n        def query_recursive(tree_index, lo, hi):\\n            if lo > j or hi < i:\\n                return 0\\n            if i <= lo and hi <= j:\\n                return self.tree[tree_index]\\n            mid = (lo + hi) // 2\\n            left_child = 2 * tree_index + 1\\n            right_child = 2 * tree_index + 2\\n            left_sum = query_recursive(left_child, lo, mid)\\n            right_sum = query_recursive(right_child, mid + 1, hi)\\n            return left_sum + right_sum\\n\\n        return query_recursive(0, 0, self.n - 1)\\n\\nnums = [1, 3, 5, 7, 9, 11]\\nseg_tree = SegmentTree(nums)\\nprint(seg_tree.query(1, 3))\\nseg_tree.update(1, 10)\\nprint(seg_tree.query(1, 3))',\n",
       "  'type': 'code'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_notebooks[0]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewing notebook 1/27\n",
      "Reviewing notebook 2/27\n",
      "Reviewing notebook 3/27\n",
      "Reviewing notebook 4/27\n",
      "Reviewing notebook 5/27\n",
      "Reviewing notebook 6/27\n",
      "Reviewing notebook 7/27\n",
      "Reviewing notebook 8/27\n",
      "Reviewing notebook 9/27\n",
      "Reviewing notebook 10/27\n",
      "Reviewing notebook 11/27\n",
      "Reviewing notebook 12/27\n",
      "Reviewing notebook 13/27\n",
      "Reviewing notebook 14/27\n",
      "Reviewing notebook 15/27\n",
      "Reviewing notebook 16/27\n",
      "Reviewing notebook 17/27\n",
      "Reviewing notebook 18/27\n",
      "Reviewing notebook 19/27\n",
      "Reviewing notebook 20/27\n",
      "Reviewing notebook 21/27\n",
      "Reviewing notebook 22/27\n",
      "Reviewing notebook 23/27\n",
      "Reviewing notebook 24/27\n",
      "Reviewing notebook 25/27\n",
      "Reviewing notebook 26/27\n",
      "Reviewing notebook 27/27\n"
     ]
    }
   ],
   "source": [
    "for i, notebook in enumerate(parsed_notebooks):\n",
    "    print(f\"Reviewing notebook {i+1}/{len(parsed_notebooks)}\")\n",
    "    # Perform the review for each notebook's messages\n",
    "    review = make_review_request(notebook)\n",
    "    # Store the review in the notebook dictionary\n",
    "    notebook['raw_review'] = review\n",
    "    # Format the review sections into a string and store it\n",
    "    formatted_review = format_review_sections(review)\n",
    "    notebook['formatted_review'] = formatted_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost for all models: $0.000\n"
     ]
    }
   ],
   "source": [
    "from src.llm_reviewer.llm_api import global_usage_manager\n",
    "global_usage_manager.print_costs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Critical Severity Issues\n",
      "# Medium Severity Issues\n",
      "**Cell 3**: The `SegmentTree` class lacks a method to handle lazy propagation for range updates.\n",
      "- **Why**: Without lazy propagation, the update method is inefficient for range updates as it updates each node individually, leading to a time complexity of O(n) for each update instead of O(log n).\n",
      "- **Where**: In the `SegmentTree` class definition.\n",
      "- **Fix**: Implement a method for lazy propagation to handle range updates efficiently.\n",
      "\n",
      "# Scoring Explanation\n",
      "The code provided in cell 3 is correct and follows good practices in terms of readability and style consistency. However, it lacks an efficient way to handle range updates, which is a significant part of segment tree functionality. The absence of lazy propagation means that the update method is not optimized for performance when dealing with range updates. This issue is of medium severity as it affects the efficiency of the code but does not render it incorrect. The code is well-formatted, and the methods are implemented correctly for point updates and range queries, which is why the score is not lower.\n",
      "\n",
      "# Score: 3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parsed_notebooks[0]['formatted_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://colab.research.google.com/drive/1ZSjvocSfnuFQY-8gGSggGUEtfnLfS_B4?revisionId=0BxmKQQ91GHhcalFrU1l4ZHppYlVtUnQ2VFptNTAzVUpGNnhNPQ'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_notebooks[0]['colab_link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Critical Severity Issues\n",
      "**Cell 3**: The `add_edge` function is incorrectly updating the adjacency list.\n",
      "- **Why**: The function creates a new `neighbours_list` every time it is called, which does not maintain the existing edges for a node.\n",
      "- **Where**: In the `add_edge` function.\n",
      "- **Fix**: Instead of creating a new list, directly append the new neighbor to the adjacency list for the node if it exists, or create a new entry if it does not.\n",
      "\n",
      "# Medium Severity Issues\n",
      "**Cell 3**: The `add_node` and `add_edge` functions do not handle the case where a node is added with an edge simultaneously.\n",
      "- **Why**: If a user tries to add an edge with a new node that is not in `node_list`, the edge will not be added, and the user is not informed why.\n",
      "- **Where**: In the `add_node` and `add_edge` functions.\n",
      "- **Fix**: Modify the `add_edge` function to add nodes to `node_list` if they are not already present before creating an edge.\n",
      "\n",
      "**Cell 3**: The `graph` function is not optimally named and its purpose is not clear.\n",
      "- **Why**: The name `graph` does not convey that it is printing the graph structure, which can be confusing.\n",
      "- **Where**: In the `graph` function definition.\n",
      "- **Fix**: Rename the `graph` function to `print_graph` to better describe its functionality.\n",
      "\n",
      "**Cell 3**: The `graph` function uses a list comprehension unnecessarily.\n",
      "- **Why**: The list comprehension `[i for i in adjacency_list[node]]` is redundant and can be replaced with `adjacency_list[node]` directly.\n",
      "- **Where**: In the `graph` function, inside the print statement.\n",
      "- **Fix**: Replace the list comprehension with the list itself.\n",
      "\n",
      "# Scoring Explanation\n",
      "The code has a critical issue with the `add_edge` function that affects the correctness of the adjacency list representation. Additionally, there are medium severity issues related to the handling of nodes and edges, function naming, and unnecessary list comprehension. These issues affect the code's readability, correctness, and best practices. However, the code is mostly correct in terms of syntax and structure, and the issues are fixable.\n",
      "\n",
      "# Score: 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(notebooks_df.iloc[2]['full_history_formatted_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_link</th>\n",
       "      <th>full_history_formatted_review</th>\n",
       "      <th>full_history_code_score</th>\n",
       "      <th>Human Code Quality</th>\n",
       "      <th>Human Language Quality</th>\n",
       "      <th>Human Reviewer Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1ZSjvo...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The header of the code cell should be \"# Assis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1nv28F...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>++The code is correct, concise and well struct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1nBjh1...</td>\n",
       "      <td># Critical Severity Issues\\n**Cell 3**: The `a...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>++ Code is clean and well structured\\n++Langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/17eg2v...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>This looks good.\\n\\nThe code could be improved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1XOkKN...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Good!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://colab.research.google.com/drive/1VmX6t...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>--The first assistant markdown has multiple gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://colab.research.google.com/drive/1CQSKk...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>--Conversation does not meet the minimum lengt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://colab.research.google.com/drive/11CEko...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>++ Code is clean and well structured \\n++ Test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://colab.research.google.com/drive/1dsE7l...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-- Incorrect use of f-string in the last print...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://colab.research.google.com/drive/1wEgUF...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>++ code is clean and well structured\\n++ comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://colab.research.google.com/drive/15AXjZ...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-- Would be better if you added few more inlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://colab.research.google.com/drive/15e4n1...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-- Code is too long and verbose. (Demo a singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://colab.research.google.com/drive/12nfkD...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-- Stick to what is asked by the user, the use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://colab.research.google.com/drive/1wAM4c...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-- Add (# Assistant) header in the code block ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://colab.research.google.com/drive/1Eopvh...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>++ everything looks good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://colab.research.google.com/drive/1OsBof...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-- Add (# Assistant) Header in your code block...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://colab.research.google.com/drive/1MYtCR...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-- a more pythonic way to do this is using f-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://colab.research.google.com/drive/14AhL8...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-- explanation is not clear\\n-- use backtick (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://colab.research.google.com/drive/17qaUh...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-- add bit more explanation (either inline com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://colab.research.google.com/drive/1jsED2...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-- use context manager to deal with files\\n-- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://colab.research.google.com/drive/13Rb92...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>++ code is clean and readable with suitable in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://colab.research.google.com/drive/1b6RV7...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-- re-check your code , the output seems wrong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://colab.research.google.com/drive/1BHcRv...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>++ Looks good \\nSuggestion : Add inline commen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://colab.research.google.com/drive/1bivSL...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>++ well structured code with appropriate inlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://colab.research.google.com/drive/1bNGIo...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>++ code and explanation are good \\n-- there is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://colab.research.google.com/drive/1efYx0...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>++ code and explanations are good \\nSuggestion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://colab.research.google.com/drive/1epNcE...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-- inadequate explanation. (Add (short)a gener...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           colab_link  \\\n",
       "0   https://colab.research.google.com/drive/1ZSjvo...   \n",
       "1   https://colab.research.google.com/drive/1nv28F...   \n",
       "2   https://colab.research.google.com/drive/1nBjh1...   \n",
       "3   https://colab.research.google.com/drive/17eg2v...   \n",
       "4   https://colab.research.google.com/drive/1XOkKN...   \n",
       "5   https://colab.research.google.com/drive/1VmX6t...   \n",
       "6   https://colab.research.google.com/drive/1CQSKk...   \n",
       "7   https://colab.research.google.com/drive/11CEko...   \n",
       "8   https://colab.research.google.com/drive/1dsE7l...   \n",
       "9   https://colab.research.google.com/drive/1wEgUF...   \n",
       "10  https://colab.research.google.com/drive/15AXjZ...   \n",
       "11  https://colab.research.google.com/drive/15e4n1...   \n",
       "12  https://colab.research.google.com/drive/12nfkD...   \n",
       "13  https://colab.research.google.com/drive/1wAM4c...   \n",
       "14  https://colab.research.google.com/drive/1Eopvh...   \n",
       "15  https://colab.research.google.com/drive/1OsBof...   \n",
       "16  https://colab.research.google.com/drive/1MYtCR...   \n",
       "17  https://colab.research.google.com/drive/14AhL8...   \n",
       "18  https://colab.research.google.com/drive/17qaUh...   \n",
       "19  https://colab.research.google.com/drive/1jsED2...   \n",
       "20  https://colab.research.google.com/drive/13Rb92...   \n",
       "21  https://colab.research.google.com/drive/1b6RV7...   \n",
       "22  https://colab.research.google.com/drive/1BHcRv...   \n",
       "23  https://colab.research.google.com/drive/1bivSL...   \n",
       "24  https://colab.research.google.com/drive/1bNGIo...   \n",
       "25  https://colab.research.google.com/drive/1efYx0...   \n",
       "26  https://colab.research.google.com/drive/1epNcE...   \n",
       "\n",
       "                        full_history_formatted_review  \\\n",
       "0   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "1   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "2   # Critical Severity Issues\\n**Cell 3**: The `a...   \n",
       "3   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "4   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "5   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "6   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "7   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "8   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "9   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "10  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "11  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "12  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "13  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "14  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "15  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "16  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "17  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "18  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "19  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "20  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "21  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "22  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "23  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "24  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "25  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "26  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "\n",
       "    full_history_code_score Human Code Quality Human Language Quality  \\\n",
       "0                         3                  4                      4   \n",
       "1                         3                  5                      3   \n",
       "2                         2                  4                      5   \n",
       "3                         4                  4                      5   \n",
       "4                         4                  5                      5   \n",
       "5                         4                  5                      3   \n",
       "6                         4                  3                      3   \n",
       "7                         4                  5                      4   \n",
       "8                         5                  3                      4   \n",
       "9                         4                  5                      4   \n",
       "10                        5                  4                      3   \n",
       "11                        5                  3                      3   \n",
       "12                        4                  3                      4   \n",
       "13                        4                  4                      3   \n",
       "14                        5                  5                      5   \n",
       "15                        4                  4                      4   \n",
       "16                        4                  3                      4   \n",
       "17                        5                  4                      3   \n",
       "18                        5                  4                      4   \n",
       "19                        4                  3                      3   \n",
       "20                        5                  5                      3   \n",
       "21                        4                  2                      3   \n",
       "22                        5                  5                      5   \n",
       "23                        5                  5                      4   \n",
       "24                        5                  4                      5   \n",
       "25                        5                  5                      5   \n",
       "26                        3                  3                      3   \n",
       "\n",
       "                              Human Reviewer Feedback  \n",
       "0   The header of the code cell should be \"# Assis...  \n",
       "1   ++The code is correct, concise and well struct...  \n",
       "2   ++ Code is clean and well structured\\n++Langua...  \n",
       "3   This looks good.\\n\\nThe code could be improved...  \n",
       "4                                          Very Good!  \n",
       "5   --The first assistant markdown has multiple gr...  \n",
       "6   --Conversation does not meet the minimum lengt...  \n",
       "7   ++ Code is clean and well structured \\n++ Test...  \n",
       "8   -- Incorrect use of f-string in the last print...  \n",
       "9   ++ code is clean and well structured\\n++ comme...  \n",
       "10  -- Would be better if you added few more inlin...  \n",
       "11  -- Code is too long and verbose. (Demo a singl...  \n",
       "12  -- Stick to what is asked by the user, the use...  \n",
       "13  -- Add (# Assistant) header in the code block ...  \n",
       "14                           ++ everything looks good  \n",
       "15  -- Add (# Assistant) Header in your code block...  \n",
       "16  -- a more pythonic way to do this is using f-s...  \n",
       "17  -- explanation is not clear\\n-- use backtick (...  \n",
       "18  -- add bit more explanation (either inline com...  \n",
       "19  -- use context manager to deal with files\\n-- ...  \n",
       "20  ++ code is clean and readable with suitable in...  \n",
       "21  -- re-check your code , the output seems wrong...  \n",
       "22  ++ Looks good \\nSuggestion : Add inline commen...  \n",
       "23  ++ well structured code with appropriate inlin...  \n",
       "24  ++ code and explanation are good \\n-- there is...  \n",
       "25  ++ code and explanations are good \\nSuggestion...  \n",
       "26  -- inadequate explanation. (Add (short)a gener...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "notebooks_df = pd.DataFrame(parsed_notebooks)\n",
    "notebooks_df['full_history_code_score'] = notebooks_df['raw_review'].apply(lambda x: x.get('score') if x is not None else None)\n",
    "notebooks_df.rename(columns={'formatted_review': 'full_history_formatted_review'}, inplace=True)\n",
    "notebooks_df = notebooks_df.merge(selected_rows_df[['file_id', 'Code Quality', 'Language Quality', 'Feedback for the Trainer']], left_on='id', right_on='file_id', how='left')\n",
    "\n",
    "notebooks_df = notebooks_df[['colab_link', 'full_history_formatted_review', 'full_history_code_score', 'Code Quality', 'Language Quality', 'Feedback for the Trainer']]\n",
    "\n",
    "notebooks_df.rename(columns={'score': 'selected_rows_score', 'Code Quality':'Human Code Quality', 'Language Quality':'Human Language Quality', 'Feedback for the Trainer': 'Human Reviewer Feedback'}, inplace=True)\n",
    "notebooks_df['colab_link'] = notebooks_df['colab_link'].str.replace('?', '#')\n",
    "from utils import DATA_DIR\n",
    "notebooks_df.to_csv(DATA_DIR + 'full_hsitory_df_code_only.csv', index=False)\n",
    "notebooks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_link</th>\n",
       "      <th>full_history_formatted_review</th>\n",
       "      <th>full_history_code_score</th>\n",
       "      <th>Human Code Quality</th>\n",
       "      <th>Human Language Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1ZSjvo...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1nv28F...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1nBjh1...</td>\n",
       "      <td># Critical Severity Issues\\n**Cell 3**: The `a...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/17eg2v...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1XOkKN...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://colab.research.google.com/drive/1VmX6t...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://colab.research.google.com/drive/1CQSKk...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://colab.research.google.com/drive/11CEko...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://colab.research.google.com/drive/1dsE7l...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://colab.research.google.com/drive/1wEgUF...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://colab.research.google.com/drive/15AXjZ...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://colab.research.google.com/drive/15e4n1...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://colab.research.google.com/drive/12nfkD...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://colab.research.google.com/drive/1wAM4c...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://colab.research.google.com/drive/1Eopvh...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://colab.research.google.com/drive/1OsBof...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://colab.research.google.com/drive/1MYtCR...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://colab.research.google.com/drive/14AhL8...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://colab.research.google.com/drive/17qaUh...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://colab.research.google.com/drive/1jsED2...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://colab.research.google.com/drive/13Rb92...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://colab.research.google.com/drive/1b6RV7...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://colab.research.google.com/drive/1BHcRv...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://colab.research.google.com/drive/1bivSL...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://colab.research.google.com/drive/1bNGIo...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://colab.research.google.com/drive/1efYx0...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://colab.research.google.com/drive/1epNcE...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           colab_link  \\\n",
       "0   https://colab.research.google.com/drive/1ZSjvo...   \n",
       "1   https://colab.research.google.com/drive/1nv28F...   \n",
       "2   https://colab.research.google.com/drive/1nBjh1...   \n",
       "3   https://colab.research.google.com/drive/17eg2v...   \n",
       "4   https://colab.research.google.com/drive/1XOkKN...   \n",
       "5   https://colab.research.google.com/drive/1VmX6t...   \n",
       "6   https://colab.research.google.com/drive/1CQSKk...   \n",
       "7   https://colab.research.google.com/drive/11CEko...   \n",
       "8   https://colab.research.google.com/drive/1dsE7l...   \n",
       "9   https://colab.research.google.com/drive/1wEgUF...   \n",
       "10  https://colab.research.google.com/drive/15AXjZ...   \n",
       "11  https://colab.research.google.com/drive/15e4n1...   \n",
       "12  https://colab.research.google.com/drive/12nfkD...   \n",
       "13  https://colab.research.google.com/drive/1wAM4c...   \n",
       "14  https://colab.research.google.com/drive/1Eopvh...   \n",
       "15  https://colab.research.google.com/drive/1OsBof...   \n",
       "16  https://colab.research.google.com/drive/1MYtCR...   \n",
       "17  https://colab.research.google.com/drive/14AhL8...   \n",
       "18  https://colab.research.google.com/drive/17qaUh...   \n",
       "19  https://colab.research.google.com/drive/1jsED2...   \n",
       "20  https://colab.research.google.com/drive/13Rb92...   \n",
       "21  https://colab.research.google.com/drive/1b6RV7...   \n",
       "22  https://colab.research.google.com/drive/1BHcRv...   \n",
       "23  https://colab.research.google.com/drive/1bivSL...   \n",
       "24  https://colab.research.google.com/drive/1bNGIo...   \n",
       "25  https://colab.research.google.com/drive/1efYx0...   \n",
       "26  https://colab.research.google.com/drive/1epNcE...   \n",
       "\n",
       "                        full_history_formatted_review  \\\n",
       "0   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "1   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "2   # Critical Severity Issues\\n**Cell 3**: The `a...   \n",
       "3   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "4   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "5   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "6   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "7   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "8   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "9   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "10  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "11  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "12  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "13  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "14  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "15  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "16  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "17  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "18  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "19  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "20  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "21  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "22  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "23  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "24  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "25  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "26  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "\n",
       "    full_history_code_score Human Code Quality Human Language Quality  \n",
       "0                         3                  4                      4  \n",
       "1                         3                  5                      3  \n",
       "2                         2                  4                      5  \n",
       "3                         4                  4                      5  \n",
       "4                         4                  5                      5  \n",
       "5                         4                  5                      3  \n",
       "6                         4                  3                      3  \n",
       "7                         4                  5                      4  \n",
       "8                         5                  3                      4  \n",
       "9                         4                  5                      4  \n",
       "10                        5                  4                      3  \n",
       "11                        5                  3                      3  \n",
       "12                        4                  3                      4  \n",
       "13                        4                  4                      3  \n",
       "14                        5                  5                      5  \n",
       "15                        4                  4                      4  \n",
       "16                        4                  3                      4  \n",
       "17                        5                  4                      3  \n",
       "18                        5                  4                      4  \n",
       "19                        4                  3                      3  \n",
       "20                        5                  5                      3  \n",
       "21                        4                  2                      3  \n",
       "22                        5                  5                      5  \n",
       "23                        5                  5                      4  \n",
       "24                        5                  4                      5  \n",
       "25                        5                  5                      5  \n",
       "26                        3                  3                      3  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_urls = \"\"\"\n",
    "https://colab.research.google.com/drive/1_lUJ5N3a8gX4pz2AEZ1LHhlLxKc-RsRG\n",
    "https://colab.research.google.com/drive/1qJPPqc7d1M4ljB2fWss3XniuCXL_-J6w\n",
    "https://colab.research.google.com/drive/1UeXB6ceNocGOSwSsOxH3ZQ2ZPFCBsQQn\n",
    "https://colab.research.google.com/drive/1cP6qzbSAWYKL8QgTNPa9S85qApJejzde\n",
    "https://colab.research.google.com/drive/1FIo_t-nNB41OVE4BqsfHC8EeMKcB3hVd\n",
    "https://colab.research.google.com/drive/1JUY9363HPsn5ChuweH_i31EzSsJPzSwX\n",
    "https://colab.research.google.com/drive/1kL_7R8kTnbT0nDuuVweaHMszel7ITPhO\n",
    "https://colab.research.google.com/drive/1yfP7u0DJjcZvthfDq-_GQcc343eTRMWM\n",
    "https://colab.research.google.com/drive/182EqzbvKd4W7-eEuAoRInPtWzMj9oVPl\n",
    "https://colab.research.google.com/drive/1CPEz-cjdkWop8Ju5Mn0Gb75sEr24UUUl\n",
    "https://colab.research.google.com/drive/189Fnel9xYNfdHXLDhwp83We0qiHvTcG-\n",
    "https://colab.research.google.com/drive/1KtSOMVTE5kj8VuId-zm-y_TZVVMQwYwZ\n",
    "https://colab.research.google.com/drive/1Unbsf2xICxBcqMFzYBbyS9NW4kVtr7Os\n",
    "\"\"\".strip().split()\n",
    "len(notebook_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreviews_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reviews_df' is not defined"
     ]
    }
   ],
   "source": [
    "df_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Task Link [Google Colab]</th>\n",
       "      <th>Code Quality</th>\n",
       "      <th>Language Quality</th>\n",
       "      <th>Feedback for the Trainer</th>\n",
       "      <th>Author Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/19/2023 12:01:41</td>\n",
       "      <td>youssef.h@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1ZSjvo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The header of the code cell should be \"# Assis...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/19/2023 12:09:35</td>\n",
       "      <td>youssef.h@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1nv28F...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>++The code is correct, concise and well struct...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/19/2023 12:31:33</td>\n",
       "      <td>youssef.h@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1nBjh1...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>++ Code is clean and well structured\\n++Langua...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1/16/2024 15:04:17</td>\n",
       "      <td>freitas.g@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1_TyU5...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>++ very good</td>\n",
       "      <td>khalid.s@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1/16/2024 15:10:21</td>\n",
       "      <td>freitas.g@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1oSndl...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>++ very well done\\n-- feel like the questions ...</td>\n",
       "      <td>zain.v@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1/16/2024 15:14:43</td>\n",
       "      <td>freitas.g@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/12soeb...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n++ very well done\\n-- feel like it's a bit t...</td>\n",
       "      <td>caram.v@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>1/16/2024 16:13:00</td>\n",
       "      <td>freitas.g@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1FKh_F...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>++ very well done</td>\n",
       "      <td>elsadek.a@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>1/16/2024 16:25:58</td>\n",
       "      <td>freitas.g@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1FXLEC...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-- the assistant is testing the user knowledge...</td>\n",
       "      <td>khalid.s@turing.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp         Email Address  \\\n",
       "0                   None                  None   \n",
       "1    12/19/2023 12:01:41  youssef.h@turing.com   \n",
       "2    12/19/2023 12:09:35  youssef.h@turing.com   \n",
       "3    12/19/2023 12:31:33  youssef.h@turing.com   \n",
       "4                   None                  None   \n",
       "..                   ...                   ...   \n",
       "514   1/16/2024 15:04:17  freitas.g@turing.com   \n",
       "515   1/16/2024 15:10:21  freitas.g@turing.com   \n",
       "516   1/16/2024 15:14:43  freitas.g@turing.com   \n",
       "517   1/16/2024 16:13:00  freitas.g@turing.com   \n",
       "518   1/16/2024 16:25:58  freitas.g@turing.com   \n",
       "\n",
       "                              Task Link [Google Colab] Code Quality  \\\n",
       "0                                                 None         None   \n",
       "1    https://colab.research.google.com/drive/1ZSjvo...            4   \n",
       "2    https://colab.research.google.com/drive/1nv28F...            5   \n",
       "3    https://colab.research.google.com/drive/1nBjh1...            4   \n",
       "4                                                 None         None   \n",
       "..                                                 ...          ...   \n",
       "514  https://colab.research.google.com/drive/1_TyU5...            5   \n",
       "515  https://colab.research.google.com/drive/1oSndl...            5   \n",
       "516  https://colab.research.google.com/drive/12soeb...            5   \n",
       "517  https://colab.research.google.com/drive/1FKh_F...            5   \n",
       "518  https://colab.research.google.com/drive/1FXLEC...            5   \n",
       "\n",
       "    Language Quality                           Feedback for the Trainer  \\\n",
       "0               None                                               None   \n",
       "1                  4  The header of the code cell should be \"# Assis...   \n",
       "2                  3  ++The code is correct, concise and well struct...   \n",
       "3                  5  ++ Code is clean and well structured\\n++Langua...   \n",
       "4               None                                               None   \n",
       "..               ...                                                ...   \n",
       "514                5                                       ++ very good   \n",
       "515                5  ++ very well done\\n-- feel like the questions ...   \n",
       "516                4  \\n++ very well done\\n-- feel like it's a bit t...   \n",
       "517                5                                  ++ very well done   \n",
       "518                2  -- the assistant is testing the user knowledge...   \n",
       "\n",
       "             Author Email  \n",
       "0                    None  \n",
       "1                    None  \n",
       "2                    None  \n",
       "3                    None  \n",
       "4                    None  \n",
       "..                    ...  \n",
       "514   khalid.s@turing.com  \n",
       "515     zain.v@turing.com  \n",
       "516    caram.v@turing.com  \n",
       "517  elsadek.a@turing.com  \n",
       "518   khalid.s@turing.com  \n",
       "\n",
       "[519 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sheets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>jsonl_link</th>\n",
       "      <th>metadata__topic</th>\n",
       "      <th>number_of_turns</th>\n",
       "      <th>duration_mins</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Task Link [Google Colab]</th>\n",
       "      <th>Code Quality</th>\n",
       "      <th>Language Quality</th>\n",
       "      <th>Feedback for the Trainer</th>\n",
       "      <th>Author Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1UeXB6...</td>\n",
       "      <td>https://drive.google.com/file/d/1GpwZJpZdS-QdH...</td>\n",
       "      <td>database &gt; transaction_management</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1/5/2024 18:31:37</td>\n",
       "      <td>zain.v@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1UeXB6...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>- missing code example in first turn, a sample...</td>\n",
       "      <td>kumbar.r@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1qJPPq...</td>\n",
       "      <td>https://drive.google.com/file/d/17faYUO_xOnLan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1/4/2024 19:52:29</td>\n",
       "      <td>zain.v@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1qJPPq...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>--It's empty.</td>\n",
       "      <td>icaro.c@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1cP6qz...</td>\n",
       "      <td>https://drive.google.com/file/d/12lm8x2QikaLaZ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1/7/2024 21:16:11</td>\n",
       "      <td>ruturaj.m@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1cP6qz...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-- No Explanation\\n-- No Headers\\n-- No Comments</td>\n",
       "      <td>patelia.a@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1CPEz-...</td>\n",
       "      <td>https://drive.google.com/file/d/15d7J16byuhmY5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/189Fne...</td>\n",
       "      <td>https://drive.google.com/file/d/1RhtPfMjxsa_n2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://colab.research.google.com/drive/1Unbsf...</td>\n",
       "      <td>https://drive.google.com/file/d/1-XsTKRyBDpGa_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://colab.research.google.com/drive/1KtSOM...</td>\n",
       "      <td>https://drive.google.com/file/d/1S7BfTUH4dfej9...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://colab.research.google.com/drive/1_lUJ5...</td>\n",
       "      <td>https://drive.google.com/file/d/1DbVKF30oMVp7V...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1/4/2024 16:21:26</td>\n",
       "      <td>freitas.g@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1_lUJ5...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-- assistant header is wrong it should be **As...</td>\n",
       "      <td>gautam.g@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://colab.research.google.com/drive/1JUY93...</td>\n",
       "      <td>https://drive.google.com/file/d/1gZERrrCwAFqEF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1/8/2024 18:18:54</td>\n",
       "      <td>freitas.g@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1JUY93...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-- really low effort, I understand that someti...</td>\n",
       "      <td>pawan.s@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://colab.research.google.com/drive/1kL_7R...</td>\n",
       "      <td>https://drive.google.com/file/d/11t58DSUzw2nXr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1/8/2024 20:29:59</td>\n",
       "      <td>freitas.g@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1kL_7R...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-- The user question is clearly a copy and pas...</td>\n",
       "      <td>pawan.s@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://colab.research.google.com/drive/1FIo_t...</td>\n",
       "      <td>https://drive.google.com/file/d/1-qHTe1xEOWSHx...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1/8/2024 16:07:48</td>\n",
       "      <td>zain.v@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1FIo_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>- Requirement was 4-8 turns only found 1.</td>\n",
       "      <td>pawan.s@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://colab.research.google.com/drive/182Eqz...</td>\n",
       "      <td>https://drive.google.com/file/d/1DKmssgFUQEJ2I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1/9/2024 10:49:45</td>\n",
       "      <td>chirag.rade-c@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/182Eqz...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>--Assistant does not have access to links \\nRa...</td>\n",
       "      <td>sudharchith.s@turing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://colab.research.google.com/drive/1yfP7u...</td>\n",
       "      <td>https://drive.google.com/file/d/1Uqg0_De6GCkH9...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1/8/2024 20:54:28</td>\n",
       "      <td>freitas.g@turing.com</td>\n",
       "      <td>https://colab.research.google.com/drive/1yfP7u...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-- the code is incorrect. I think you copied t...</td>\n",
       "      <td>toh.y@turing.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            task_link  \\\n",
       "0   https://colab.research.google.com/drive/1UeXB6...   \n",
       "1   https://colab.research.google.com/drive/1qJPPq...   \n",
       "2   https://colab.research.google.com/drive/1cP6qz...   \n",
       "3   https://colab.research.google.com/drive/1CPEz-...   \n",
       "4   https://colab.research.google.com/drive/189Fne...   \n",
       "5   https://colab.research.google.com/drive/1Unbsf...   \n",
       "6   https://colab.research.google.com/drive/1KtSOM...   \n",
       "7   https://colab.research.google.com/drive/1_lUJ5...   \n",
       "8   https://colab.research.google.com/drive/1JUY93...   \n",
       "9   https://colab.research.google.com/drive/1kL_7R...   \n",
       "10  https://colab.research.google.com/drive/1FIo_t...   \n",
       "11  https://colab.research.google.com/drive/182Eqz...   \n",
       "12  https://colab.research.google.com/drive/1yfP7u...   \n",
       "\n",
       "                                           jsonl_link  \\\n",
       "0   https://drive.google.com/file/d/1GpwZJpZdS-QdH...   \n",
       "1   https://drive.google.com/file/d/17faYUO_xOnLan...   \n",
       "2   https://drive.google.com/file/d/12lm8x2QikaLaZ...   \n",
       "3   https://drive.google.com/file/d/15d7J16byuhmY5...   \n",
       "4   https://drive.google.com/file/d/1RhtPfMjxsa_n2...   \n",
       "5   https://drive.google.com/file/d/1-XsTKRyBDpGa_...   \n",
       "6   https://drive.google.com/file/d/1S7BfTUH4dfej9...   \n",
       "7   https://drive.google.com/file/d/1DbVKF30oMVp7V...   \n",
       "8   https://drive.google.com/file/d/1gZERrrCwAFqEF...   \n",
       "9   https://drive.google.com/file/d/11t58DSUzw2nXr...   \n",
       "10  https://drive.google.com/file/d/1-qHTe1xEOWSHx...   \n",
       "11  https://drive.google.com/file/d/1DKmssgFUQEJ2I...   \n",
       "12  https://drive.google.com/file/d/1Uqg0_De6GCkH9...   \n",
       "\n",
       "                      metadata__topic number_of_turns duration_mins  batch_id  \\\n",
       "0   database > transaction_management               2            40         4   \n",
       "1                                 NaN               1           NaN         5   \n",
       "2                                 NaN               1           NaN         5   \n",
       "3                                 NaN               5           NaN         5   \n",
       "4                                 NaN               8           NaN         5   \n",
       "5                                 NaN               5           NaN         5   \n",
       "6                                 NaN               4           NaN         5   \n",
       "7                                 NaN               1           NaN         5   \n",
       "8                                 NaN               1           NaN         5   \n",
       "9                                 NaN               2           NaN         5   \n",
       "10                                NaN               2           NaN         5   \n",
       "11                                NaN               4           NaN         5   \n",
       "12                                NaN               2           NaN         5   \n",
       "\n",
       "            Timestamp             Email Address  \\\n",
       "0   1/5/2024 18:31:37         zain.v@turing.com   \n",
       "1   1/4/2024 19:52:29         zain.v@turing.com   \n",
       "2   1/7/2024 21:16:11      ruturaj.m@turing.com   \n",
       "3                 NaN                       NaN   \n",
       "4                 NaN                       NaN   \n",
       "5                 NaN                       NaN   \n",
       "6                 NaN                       NaN   \n",
       "7   1/4/2024 16:21:26      freitas.g@turing.com   \n",
       "8   1/8/2024 18:18:54      freitas.g@turing.com   \n",
       "9   1/8/2024 20:29:59      freitas.g@turing.com   \n",
       "10  1/8/2024 16:07:48         zain.v@turing.com   \n",
       "11  1/9/2024 10:49:45  chirag.rade-c@turing.com   \n",
       "12  1/8/2024 20:54:28      freitas.g@turing.com   \n",
       "\n",
       "                             Task Link [Google Colab] Code Quality  \\\n",
       "0   https://colab.research.google.com/drive/1UeXB6...            3   \n",
       "1   https://colab.research.google.com/drive/1qJPPq...            1   \n",
       "2   https://colab.research.google.com/drive/1cP6qz...            2   \n",
       "3                                                 NaN          NaN   \n",
       "4                                                 NaN          NaN   \n",
       "5                                                 NaN          NaN   \n",
       "6                                                 NaN          NaN   \n",
       "7   https://colab.research.google.com/drive/1_lUJ5...            1   \n",
       "8   https://colab.research.google.com/drive/1JUY93...            2   \n",
       "9   https://colab.research.google.com/drive/1kL_7R...            1   \n",
       "10  https://colab.research.google.com/drive/1FIo_t...            1   \n",
       "11  https://colab.research.google.com/drive/182Eqz...            2   \n",
       "12  https://colab.research.google.com/drive/1yfP7u...            2   \n",
       "\n",
       "   Language Quality                           Feedback for the Trainer  \\\n",
       "0                 3  - missing code example in first turn, a sample...   \n",
       "1                 1                                      --It's empty.   \n",
       "2                 1   -- No Explanation\\n-- No Headers\\n-- No Comments   \n",
       "3               NaN                                                NaN   \n",
       "4               NaN                                                NaN   \n",
       "5               NaN                                                NaN   \n",
       "6               NaN                                                NaN   \n",
       "7                 1  -- assistant header is wrong it should be **As...   \n",
       "8                 2  -- really low effort, I understand that someti...   \n",
       "9                 1  -- The user question is clearly a copy and pas...   \n",
       "10                1          - Requirement was 4-8 turns only found 1.   \n",
       "11                2  --Assistant does not have access to links \\nRa...   \n",
       "12                5  -- the code is incorrect. I think you copied t...   \n",
       "\n",
       "                Author Email  \n",
       "0        kumbar.r@turing.com  \n",
       "1         icaro.c@turing.com  \n",
       "2       patelia.a@turing.com  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "5                        NaN  \n",
       "6                        NaN  \n",
       "7        gautam.g@turing.com  \n",
       "8         pawan.s@turing.com  \n",
       "9         pawan.s@turing.com  \n",
       "10        pawan.s@turing.com  \n",
       "11  sudharchith.s@turing.com  \n",
       "12          toh.y@turing.com  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_rows_df = delivered_df[delivered_df['task_link'].isin(notebook_urls)]\n",
    "selected_rows_df = selected_rows_df.merge(reviews_sheets_df, left_on='task_link', right_on='Task Link [Google Colab]', how='left')\n",
    "\n",
    "selected_rows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and parsing notebook 1/13 (File ID: 1UeXB6ceNocGOSwSsOxH3ZQ2ZPFCBsQQn, Revision ID: 0BxmKQQ91GHhcV2ZiWlJKM0g4WHkwVXkzMUhuUVg1Q1hselpJPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 2/13 (File ID: 1qJPPqc7d1M4ljB2fWss3XniuCXL_-J6w, Revision ID: 0BxmKQQ91GHhcZEs4VmlqUU5VQTlIcEU3RVpMVDNKckUyQ0kwPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 3/13 (File ID: 1cP6qzbSAWYKL8QgTNPa9S85qApJejzde, Revision ID: 0BxmKQQ91GHhcbElURFdqUGlzbnlHaHhpTnQ4UDNWbHJ3UVVjPQ)\n",
      "Download progress: 100%.\n",
      "Filling out missing header...\n",
      "Downloading and parsing notebook 4/13 (File ID: 1CPEz-cjdkWop8Ju5Mn0Gb75sEr24UUUl, Revision ID: None)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 5/13 (File ID: 189Fnel9xYNfdHXLDhwp83We0qiHvTcG-, Revision ID: None)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 6/13 (File ID: 1Unbsf2xICxBcqMFzYBbyS9NW4kVtr7Os, Revision ID: None)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 7/13 (File ID: 1KtSOMVTE5kj8VuId-zm-y_TZVVMQwYwZ, Revision ID: None)\n",
      "Download progress: 100%.\n",
      "Filling out missing header...\n",
      "Downloading and parsing notebook 8/13 (File ID: 1_lUJ5N3a8gX4pz2AEZ1LHhlLxKc-RsRG, Revision ID: 0BxmKQQ91GHhcVnoxR28rOGVVdlFvQVQ3bndDTVJwTHUweGY4PQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 9/13 (File ID: 1JUY9363HPsn5ChuweH_i31EzSsJPzSwX, Revision ID: 0BxmKQQ91GHhcN3ViTitrMVh2Vi82V3l6a2tpaGFWWnBLYlhZPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 10/13 (File ID: 1kL_7R8kTnbT0nDuuVweaHMszel7ITPhO, Revision ID: 0BxmKQQ91GHhcUXIrSWdkaFM3eTBjNkVkei9WMmhZY0EycSs4PQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 11/13 (File ID: 1FIo_t-nNB41OVE4BqsfHC8EeMKcB3hVd, Revision ID: 0BxmKQQ91GHhcSW81WFNNVHdYUjFHQmZsK25yQU9QdzZpeUlVPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 12/13 (File ID: 182EqzbvKd4W7-eEuAoRInPtWzMj9oVPl, Revision ID: 0BxmKQQ91GHhcam5WdFkrVFE0bkFQb2l2L1JOUzhrZGZ5Q1dRPQ)\n",
      "Download progress: 100%.\n",
      "Downloading and parsing notebook 13/13 (File ID: 1yfP7u0DJjcZvthfDq-_GQcc343eTRMWM, Revision ID: 0BxmKQQ91GHhcaDhndXZza1FySklWVGVkQldjcjRnbXdTUVJjPQ)\n",
      "Download progress: 100%.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add a new column to the DataFrame for the file IDs\n",
    "selected_rows_df['file_id'] = selected_rows_df['task_link'].apply(get_file_id_from_task_link)\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "selected_rows_df['revision'] = selected_rows_df.apply(lambda row: get_revision_before_timestamp(row['file_id'], row['Timestamp']) if row['file_id'] is not None else None, axis=1)\n",
    "selected_rows_df['task_link_rev'] = selected_rows_df.apply(lambda row: append_revision_id_to_task_link(row['task_link'], row['revision']), axis=1)\n",
    "\n",
    "parsed_notebooks = []\n",
    "for i, (index, row) in enumerate(selected_rows_df.iterrows()):\n",
    "    file_id = row['file_id']\n",
    "    revision_id = row['revision'].get('id') if row['revision'] is not None else None\n",
    "    print(f\"Downloading and parsing notebook {i+1}/{len(selected_rows_df)} (File ID: {file_id}, Revision ID: {revision_id})\")\n",
    "    parsed_notebook = download_and_parse_notebook(service_account_path, file_id, revision_id)\n",
    "    parsed_notebooks.append(parsed_notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from utils import DATA_DIR\n",
    "\n",
    "# Create directory if it does not exist\n",
    "selected_notebooks_dir = os.path.join(DATA_DIR, 'selected_for_eval_notebooks')\n",
    "os.makedirs(selected_notebooks_dir, exist_ok=True)\n",
    "\n",
    "# Pickle dump the parsed_notebooks\n",
    "with open(os.path.join(selected_notebooks_dir, 'parsed_notebooks.pkl'), 'wb') as f:\n",
    "    pickle.dump(parsed_notebooks, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from utils import DATA_DIR\n",
    "\n",
    "# Pickle load the parsed_notebooks\n",
    "with open(os.path.join(selected_notebooks_dir, 'parsed_notebooks.pkl'), 'rb') as f:\n",
    "    parsed_notebooks = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def review_notebook(notebook):\n",
    "    review = make_review_request(notebook)\n",
    "    formatted_review = format_review_sections(review)\n",
    "    return review, formatted_review\n",
    "\n",
    "def review_all_notebooks(parsed_notebooks):\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(review_notebook, notebook): i for i, notebook in enumerate(parsed_notebooks)}\n",
    "        progress_bar = tqdm(as_completed(futures), total=len(parsed_notebooks), desc=\"Reviewing Notebooks\", leave=False)\n",
    "        for future in progress_bar:\n",
    "            review, formatted_review = future.result()\n",
    "            notebook_index = futures[future]\n",
    "            parsed_notebooks[notebook_index]['raw_review'] = review\n",
    "            parsed_notebooks[notebook_index]['formatted_review'] = formatted_review\n",
    "        progress_bar.close()\n",
    "    return parsed_notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1JUY9363HPsn5ChuweH_i31EzSsJPzSwX', 'colab_link': 'https://colab.research.google.com/drive/1JUY9363HPsn5ChuweH_i31EzSsJPzSwX', 'revision_id': '0BxmKQQ91GHhcN3ViTitrMVh2Vi82V3l6a2tpaGFWWnBLYlhZPQ', 'metadata': {'topic': 'debugging_and_tracing', 'type': 'query'}, 'messages': [{'role': 'User', 'content': 'Hi, I am getting error running the code: The generated image exceeds the limit. How to solve it?\\n```python\\nPaddleHub2.4.0, PaddlePaddle2.5.2\\nSystem environment: Windows\\npython version: 3.9.18\\nError report: In the prediction code example, an error is reported after running images = module.generate_image(text_prompts=text_prompts, style=\\'oil painting\\', output_dir=\\'./ernie_vilg_out/\\')\\nTraceback (most recent call last):\\nFile \"\", line 1, in\\nFile \"C:\\\\Users\\\\k\\\\anaconda3\\\\envs\\\\wm\\\\lib\\\\site-packages\\\\paddlehub\\\\compat\\\\paddle_utils.py\", line 221, in runner\\nreturn func(*args, **kwargs)\\nFile \"C:\\\\Users\\\\k.paddlehub\\\\modules\\\\ernie_vilg\\\\module.py\", line 121, in generate_image\\nraise RuntimeError(res[\\'msg\\'])\\nRuntimeError: generated image exceeds limit\\n\\n```', 'type': 'markdown'}, {'role': 'Assistant', 'content': 'Could you provide more information about the script and anaconda environment?', 'type': 'markdown'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5931cb8945584c99a4a57b87afde7f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reviewing Notebooks:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for p in parsed_notebooks:\n",
    "    if '1JUY9' in p['colab_link']:\n",
    "        print(p)\n",
    "\n",
    "pp = review_all_notebooks([p for p in parsed_notebooks if '1JUY9' in p['colab_link']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '1JUY9363HPsn5ChuweH_i31EzSsJPzSwX',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1JUY9363HPsn5ChuweH_i31EzSsJPzSwX',\n",
       "  'revision_id': '0BxmKQQ91GHhcN3ViTitrMVh2Vi82V3l6a2tpaGFWWnBLYlhZPQ',\n",
       "  'metadata': {'topic': 'debugging_and_tracing', 'type': 'query'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': 'Hi, I am getting error running the code: The generated image exceeds the limit. How to solve it?\\n```python\\nPaddleHub2.4.0, PaddlePaddle2.5.2\\nSystem environment: Windows\\npython version: 3.9.18\\nError report: In the prediction code example, an error is reported after running images = module.generate_image(text_prompts=text_prompts, style=\\'oil painting\\', output_dir=\\'./ernie_vilg_out/\\')\\nTraceback (most recent call last):\\nFile \"\", line 1, in\\nFile \"C:\\\\Users\\\\k\\\\anaconda3\\\\envs\\\\wm\\\\lib\\\\site-packages\\\\paddlehub\\\\compat\\\\paddle_utils.py\", line 221, in runner\\nreturn func(*args, **kwargs)\\nFile \"C:\\\\Users\\\\k.paddlehub\\\\modules\\\\ernie_vilg\\\\module.py\", line 121, in generate_image\\nraise RuntimeError(res[\\'msg\\'])\\nRuntimeError: generated image exceeds limit\\n\\n```',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'Could you provide more information about the script and anaconda environment?',\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [],\n",
       "   'could_have_been_better_issues': [],\n",
       "   'scoring_explanation': 'The conversation provided does not contain any code generated by the AI Assistant. The user has presented an issue with their code, and the Assistant has responded by asking for more information. Since there is no code to evaluate, no issues can be identified, and the score defaults to null as per the guidelines.',\n",
       "   'score': None},\n",
       "  'formatted_review': '# Critical Severity Issues\\n# Medium Severity Issues\\n# Scoring Explanation\\nThe conversation provided does not contain any code generated by the AI Assistant. The user has presented an issue with their code, and the Assistant has responded by asking for more information. Since there is no code to evaluate, no issues can be identified, and the score defaults to null as per the guidelines.\\n\\n# Score: None\\n\\n'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49e78cd6b964213ae2db6345ada8149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reviewing Notebooks:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '1UeXB6ceNocGOSwSsOxH3ZQ2ZPFCBsQQn',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1UeXB6ceNocGOSwSsOxH3ZQ2ZPFCBsQQn',\n",
       "  'revision_id': '0BxmKQQ91GHhcV2ZiWlJKM0g4WHkwVXkzMUhuUVg1Q1hselpJPQ',\n",
       "  'metadata': {'topic': 'database > transaction_management',\n",
       "   'type': 'query',\n",
       "   'target_turns': '2'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': 'How do I start a transaction in SQLAlchemy?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'There are actually 2 types of SQLAlchemy transactions\\n\\n\\n1.   Core (low level SQL query)\\n2.   ORM ( Objects relationship mapping)\\n\\n\\nHere are the steps to start transaction in SQLAlchemy Core.\\n\\nSTEPS\\n\\n1.   Create an Engine\\n\\n     An `Engine` is a source of connectivity to a particular database.\\n\\n2.   Establish Connection\\n\\n     Use the `connect()` method of the `Engine` to establish a connection to the database.\\n\\n3.   Begin transaction\\n\\n     Use the `begin()` method on the connection object to start a transaction.\\n\\n4.   Perform Operation\\n\\n     Execute your database operations (inserts, updates, deletes, etc.)\\n\\n4.   Commit or Rollback Transaction\\n\\n       After performing the required operations, commit the transaction to make the changes permanent or rollback to discard the changes.\\n       \\n5.   close the connection',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Can you create python script for the same?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Sure , Please check the below script.\\n\\nconsidering `user` table with 'id','name','age' columns for transaction.\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String\\n\\n# Step 1: Create an Engine\\nengine = create_engine(\\'sqlite:///:memory:\\')\\n\\n# Step 2: Create a Connection\\nconnection = engine.connect()\\n\\n# Step 3: Begin a Transaction\\ntransaction = connection.begin()\\n\\n# Step 4: Perform Operations\\nmetadata = MetaData()\\n\\nusers = Table(\\'users\\', metadata,\\n    Column(\\'id\\', Integer, primary_key=True),\\n    Column(\\'name\\', String),\\n    Column(\\'age\\', Integer)\\n)\\n\\nmetadata.create_all(engine)\\n\\n# Insert data into the \\'users\\' table\\nins = users.insert().values(name=\\'Ravi\\', age=26)\\nresult = connection.execute(ins)\\n\\n# Step 5: Commit or Rollback\\ntry:\\n    transaction.commit()\\nexcept Exception as e:\\n    transaction.rollback()\\n    print(f\"Error: {e}\")\\nfinally:\\n    # Close the connection\\n    connection.close()',\n",
       "    'type': 'code'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [{'cell_position': 5,\n",
       "     'what': 'Exception handling is too broad.',\n",
       "     'why': 'Catching a general Exception is not a best practice as it can make debugging harder by catching unexpected exceptions and potentially hiding bugs.',\n",
       "     'where': 'In the `try` block where `transaction.commit()` is called.',\n",
       "     'fix': 'Catch specific exceptions such as `sqlalchemy.exc.SQLAlchemyError` to handle known database errors.'},\n",
       "    {'cell_position': 5,\n",
       "     'what': 'The transaction is not being used within a context manager.',\n",
       "     'why': 'Using a context manager for the transaction ensures that resources are properly managed and the transaction is correctly committed or rolled back, even if an error occurs.',\n",
       "     'where': 'In the transaction handling section.',\n",
       "     'fix': 'Use the `with` statement to ensure the transaction is automatically committed or rolled back.'}],\n",
       "   'could_have_been_better_issues': [{'cell_position': 5,\n",
       "     'what': 'The code does not handle the case where the table already exists.',\n",
       "     'why': \"If the 'users' table already exists, `metadata.create_all(engine)` will not create any issues, but it is not efficient to attempt to create tables that already exist.\",\n",
       "     'where': 'Before calling `metadata.create_all(engine)`.',\n",
       "     'fix': 'Check if the table already exists before attempting to create it.'},\n",
       "    {'cell_position': 5,\n",
       "     'what': \"The code does not explicitly define a primary key for the 'users' table.\",\n",
       "     'why': \"While the 'id' column is intended to be the primary key, it is not explicitly set as such in the code.\",\n",
       "     'where': \"In the `Table` definition for 'users'.\",\n",
       "     'fix': \"Add `primary_key=True` to the `Column` definition for 'id'.\"},\n",
       "    {'cell_position': 5,\n",
       "     'what': 'The code does not show how to handle the connection in case of an error after it is opened.',\n",
       "     'why': 'If an error occurs after the connection is opened but before the `try` block, the connection would not be closed, potentially leading to resource leaks.',\n",
       "     'where': 'After opening the connection and before the `try` block.',\n",
       "     'fix': 'Use a context manager to ensure the connection is closed even if an error occurs before the `try` block.'}],\n",
       "   'scoring_explanation': \"The code provided by the Assistant is correct and functional, satisfying the user's request for a script to handle transactions in SQLAlchemy. However, there are some medium severity issues related to exception handling and the use of context managers that could lead to better resource management and error handling. Additionally, there are minor improvements suggested for checking table existence, defining primary keys, and handling connections which would adhere to best practices and improve the code's robustness. The conversation is complete, and the user's request is fully satisfied with the provided code.\",\n",
       "   'score': 4},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n**Cell 5**: Exception handling is too broad.\\n- **Why**: Catching a general Exception is not a best practice as it can make debugging harder by catching unexpected exceptions and potentially hiding bugs.\\n- **Where**: In the `try` block where `transaction.commit()` is called.\\n- **Fix**: Catch specific exceptions such as `sqlalchemy.exc.SQLAlchemyError` to handle known database errors.\\n\\n**Cell 5**: The transaction is not being used within a context manager.\\n- **Why**: Using a context manager for the transaction ensures that resources are properly managed and the transaction is correctly committed or rolled back, even if an error occurs.\\n- **Where**: In the transaction handling section.\\n- **Fix**: Use the `with` statement to ensure the transaction is automatically committed or rolled back.\\n\\n# Scoring Explanation\\nThe code provided by the Assistant is correct and functional, satisfying the user's request for a script to handle transactions in SQLAlchemy. However, there are some medium severity issues related to exception handling and the use of context managers that could lead to better resource management and error handling. Additionally, there are minor improvements suggested for checking table existence, defining primary keys, and handling connections which would adhere to best practices and improve the code's robustness. The conversation is complete, and the user's request is fully satisfied with the provided code.\\n\\n# Score: 4\\n\\n\"},\n",
       " {'id': '1qJPPqc7d1M4ljB2fWss3XniuCXL_-J6w',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1qJPPqc7d1M4ljB2fWss3XniuCXL_-J6w',\n",
       "  'revision_id': '0BxmKQQ91GHhcZEs4VmlqUU5VQTlIcEU3RVpMVDNKckUyQ0kwPQ',\n",
       "  'metadata': {'topic': 'deep_learning > neural_network_concepts',\n",
       "   'type': 'modification',\n",
       "   'target_turns': '2+'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': \"I have a TensorFlow model and I need to switch the optimizer from SGD to Adam with a learning rate of 0.001. Here's the snippet of my current setup:\\n```python\\nimport tensorflow as tf\\n\\nmodel = tf.keras.models.Sequential([...])\\nmodel.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\\n```\\nHow should I change the optimizer to Adam with the specified learning rate?\",\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [],\n",
       "   'could_have_been_better_issues': [],\n",
       "   'scoring_explanation': \"The conversation provided does not include any code generated by the AI Assistant. The user has presented a code snippet and a question, but there is no reply from the AI Assistant to evaluate. Therefore, no issues can be identified, and no score can be assigned to the AI Assistant's performance in terms of code quality.\",\n",
       "   'score': None},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n# Scoring Explanation\\nThe conversation provided does not include any code generated by the AI Assistant. The user has presented a code snippet and a question, but there is no reply from the AI Assistant to evaluate. Therefore, no issues can be identified, and no score can be assigned to the AI Assistant's performance in terms of code quality.\\n\\n# Score: None\\n\\n\"},\n",
       " {'id': '1cP6qzbSAWYKL8QgTNPa9S85qApJejzde',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1cP6qzbSAWYKL8QgTNPa9S85qApJejzde',\n",
       "  'revision_id': '0BxmKQQ91GHhcbElURFdqUGlzbnlHaHhpTnQ4UDNWbHJ3UVVjPQ',\n",
       "  'metadata': {'topic': 'unit_testing_methodology > test_ai_and_ml_models',\n",
       "   'type': 'modification',\n",
       "   'target_turns': '1'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': \"Hey, I've got this function to test a machine learning model's accuracy, but I need to add a part where it also returns the confusion matrix. Can you help me tweak it? Here's the code: ```def test_model_accuracy(model, test_data, test_labels): return model.score(test_data, test_labels)```\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'from sklearn.metrics import confusion_matrix\\ndef test_model_accuracy(model, test_data, test_labels):\\n  predict_labels = model.predict(test_data)\\n  return confusion_matrix(test_labels, predict_labels)',\n",
       "    'type': 'code'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [{'cell_position': 2,\n",
       "     'what': \"The function `test_model_accuracy` no longer returns the model's accuracy.\",\n",
       "     'why': \"The user requested to add functionality to return the confusion matrix along with the model's accuracy, but the modification removed the accuracy return value.\",\n",
       "     'where': 'In the function `test_model_accuracy`.',\n",
       "     'fix': 'Modify the function to return both the accuracy and the confusion matrix.'}],\n",
       "   'could_have_been_better_issues': [{'cell_position': 2,\n",
       "     'what': 'The function name `test_model_accuracy` is no longer fully descriptive.',\n",
       "     'why': 'The function now returns a confusion matrix, which is not solely about accuracy.',\n",
       "     'where': 'In the function definition `test_model_accuracy`.',\n",
       "     'fix': 'Rename the function to reflect its extended functionality, such as `test_model_performance`.'},\n",
       "    {'cell_position': 2,\n",
       "     'what': 'The code does not include a comment or documentation.',\n",
       "     'why': 'Comments or documentation would help explain the purpose and usage of the function, especially since it has been modified to return additional information.',\n",
       "     'where': 'Inside the function `test_model_accuracy`.',\n",
       "     'fix': \"Add a docstring to the function explaining the parameters, the return values, and the function's purpose.\"}],\n",
       "   'scoring_explanation': \"The code provided by the Assistant is correct in terms of syntax and would successfully return a confusion matrix. However, it does not satisfy the user's request fully because it omits the original functionality of returning the model's accuracy. This is a medium severity issue because it directly affects the user's needs and the flow of the conversation. The function name and lack of comments are minor issues that do not significantly impact the functionality but could improve readability and clarity.\",\n",
       "   'score': 3},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n**Cell 2**: The function `test_model_accuracy` no longer returns the model's accuracy.\\n- **Why**: The user requested to add functionality to return the confusion matrix along with the model's accuracy, but the modification removed the accuracy return value.\\n- **Where**: In the function `test_model_accuracy`.\\n- **Fix**: Modify the function to return both the accuracy and the confusion matrix.\\n\\n# Scoring Explanation\\nThe code provided by the Assistant is correct in terms of syntax and would successfully return a confusion matrix. However, it does not satisfy the user's request fully because it omits the original functionality of returning the model's accuracy. This is a medium severity issue because it directly affects the user's needs and the flow of the conversation. The function name and lack of comments are minor issues that do not significantly impact the functionality but could improve readability and clarity.\\n\\n# Score: 3\\n\\n\"},\n",
       " {'id': '1CPEz-cjdkWop8Ju5Mn0Gb75sEr24UUUl',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1CPEz-cjdkWop8Ju5Mn0Gb75sEr24UUUl',\n",
       "  'revision_id': None,\n",
       "  'metadata': {'topic': 'debugging_and_tracing', 'target_turns': '1-5'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': \"Hello! I've been preparing for backend developer interviews, and I'm currently working on improving my skills in debugging and fixing code, especially in Python. I've been struggling with identifying common logical errors in Python loops during interview challenges. I want to make sure I can handle those scenarios effectively.\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Great, let's dive into it. Could you share a code snippet or describe a specific loop challenge you've encountered recently? That way, we can work through it together.\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': \"Sure! In one of the challenges, I had to implement a loop to iterate over a list of numbers and perform a specific operation. However, my code is not producing the expected output, and I'm having a hard time figuring out where I went wrong. Here is my code:\\n\\n```python\\nnumbers = [1, 2, 3, 4, 5]\\nresult = 0\\n\\nfor num in numbers:\\n    result = result * 2 + num\\n\\nprint(result)\\n```\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Thanks for sharing your code. I can see the loop is intended to perform a specific operation on each number in the list. The issue might be related to the order of operations or the initial value of `result`. Let's walk through the code step by step and identify any logical errors.\\n\\nFirst, let's break down the loop. It seems like you're doubling the current result and adding the next number in each iteration. However, the initial value of `result` is 0, which might be causing unexpected behavior. It's a common mistake, and adjusting the initial value should help. Try initializing `result` with 1 instead of 0 and see if that resolves the problem.\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'It worked! The output is now as expected. Thanks a lot for your help. I appreciate the guidance. Here is the updated version:\\n\\n```python\\nnumbers = [1, 2, 3, 4, 5]\\nresult = 1\\n\\nfor num in numbers:\\n    result = result * 2 + num\\n\\nprint(result)\\n\\n```',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"You're welcome! For your practice how about we work on a scenario where you need to handle exceptions in a function that performs division? I'll provide a starting point, and you can take it from there. Here's a simple function that divides two numbers:\\n\\n```python\\n  def divide_numbers(a, b):\\n    result = a / b\\n    return result\\n ```\\n\\n Your task is to enhance this function by adding appropriate error handling to address potential issues, such as division by zero. How would you approach this?\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'I see. I\\'ll need to add a try-except block to catch any potential division by zero errors. Here is my updated code:\\n\\n```python\\ndef divide_numbers(a, b):\\n    try:\\n        result = a / b\\n        return result\\n    except ZeroDivisionError:\\n        print(\"Division by zero is not allowed.\")\\n        return None\\n\\n\\n```',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"That looks like a solid modification! You've added a try-except block to handle the ZeroDivisionError. Now, if someone tries to divide by zero, the function will print an error message and return None. Great job!\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Thank you! I appreciate your guidance. This was a helpful exercise.',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"You're welcome! I'm here to help anytime you have more coding challenges or questions. Keep up the good work with your interview preparation, and feel free to reach out if there's anything else you'd like to cover.\",\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [],\n",
       "   'could_have_been_better_issues': [],\n",
       "   'scoring_explanation': \"In this conversation, the Assistant did not generate any code but rather provided guidance and feedback on the code shared by the User. The Assistant's responses were focused on helping the User debug and improve their code, which they did effectively. Since there was no code generated by the Assistant to evaluate, there are no issues to report. The conversation was complete, and the User's request was fully satisfied with the guidance provided.\",\n",
       "   'score': 5},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n# Scoring Explanation\\nIn this conversation, the Assistant did not generate any code but rather provided guidance and feedback on the code shared by the User. The Assistant's responses were focused on helping the User debug and improve their code, which they did effectively. Since there was no code generated by the Assistant to evaluate, there are no issues to report. The conversation was complete, and the User's request was fully satisfied with the guidance provided.\\n\\n# Score: 5\\n\\n\"},\n",
       " {'id': '189Fnel9xYNfdHXLDhwp83We0qiHvTcG-',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/189Fnel9xYNfdHXLDhwp83We0qiHvTcG-',\n",
       "  'revision_id': None,\n",
       "  'metadata': {'topic': 'debugging_and_tracing', 'target_turns': '6-10'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': 'I have a large log file about some network activity in my application, how can I use pandas to parse and analyse this large log files?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"In the step-by-step guide below, you can see a generic way of parsing large log files using Python's pandas:\\n\\n1. **Install**: you can install it using.\\n    ```bash\\n    pip install pandas\\n    ```\\n2. **Reading the log file**: you can use `pandas`' `read_csv` or `read_table` function to read the log file into a DataFrame.\\n    ```python\\n    import pandas as pd\\n\\n    log_file_path = 'path/to/your/logfile.log'\\n\\n    df = pd.read_csv(log_file_path, delimiter='\\\\t', header=None, names=['column1', 'column2', ...])\\n    ```\\n3. **Explore and Analyze data**: there are various pandas functions to explore and analyze it.\\n    ```python\\n    print(df.head())\\n\\n    print(df.describe())\\n\\n    print(df['column1'].value_counts())\\n\\n    filtered_data = df[df['column2'] > 100]\\n\\n    grouped_data = df.groupby('column1').agg({'column2': 'mean', 'column3': 'count'})\\n    ```\\n4. **Handle large files**: consider using chucks using the `chucksize` parameter in `read_csv`.\\n    ```python\\n    chunk_size = 10000  # Adjust based on your file size\\n    chunks = pd.read_csv(log_file_path, delimiter='\\\\t', header=None, names=['column1', 'column2', ...], chunksize=chunk_size)\\n\\n    for chunk in chunks:\\n        # Process each chunk\\n    ```\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Can I create an hour graph to see the logs? My data contains the \"timestamp\" attached.',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'You can integrate your pandas script with `matplotlib` and generate an chart with the plot the mean of each hour. Here is an example:',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"import pandas as pd\\nimport matplotlib.pyplot as plt\\n\\nlog_file_path = 'path/to/your/logfile.log'\\n\\ndf = pd.read_csv(\\n    log_file_path,\\n    delimiter = '\\\\t',\\n    header = None,\\n    names = ['timestamp', 'column1', 'column2'],\\n    parse_dates = ['timestamp'],\\n    date_parser = pd.to_datetime\\n)\\n\\ndf.set_index('timestamp', inplace = True)\\n\\nhourly_data = df.resample('H').mean()\\nhourly_data['column1'].plot(kind = 'line')\\nplt.show()\",\n",
       "    'type': 'code'},\n",
       "   {'role': 'User',\n",
       "    'content': 'How can I discover an anomaly on my data?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'There are several anomaly detection techniques that could be used to identify unusual patternns our outliers that deviate from the norm data.\\n\\nIn the code below, we use an `IsolationForest` that uses binary trees, which are ideal for high volume data.',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"from sklearn.ensemble import IsolationForest\\n\\nmodel = IsolationForest(contamination=0.05)\\ndf['is_outlier'] = model.fit_predict(df[['feature1', 'feature2']])\",\n",
       "    'type': 'code'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Going beyond suspicious network, how can I find patterns in my log data?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'Similar to the anomaly detection techniques, there are also numerous techniques to discover interesting patterns in large datasets. In the example below, we use an example of association rule mining to find these patterns:',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'from mlxtend.frequent_patterns import apriori\\nfrom mlxtend.frequent_patterns import association_rules\\n\\nfrequent_itemsets = apriori(df, min_support=0.1, use_colnames=True)\\nrules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)',\n",
       "    'type': 'code'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Can we cluster them using Kmeans?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'To group similar data points, revealing natural patterns or categories, K-means is a great algorithm to do it. Here is an example in Python:',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"from sklearn.cluster import KMeans\\n\\nkmeans = KMeans(n_clusters=3)\\ndf['cluster'] = kmeans.fit_predict(df[['feature1', 'feature2']])\",\n",
       "    'type': 'code'},\n",
       "   {'role': 'User',\n",
       "    'content': 'How can I effectively deal with missing data in my dataset?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'You can use methods such as imputation (filling missing values with estimated ones), removing missing values, or leveraging advanced techniques like machine learning imputation.\\n\\nIn pandas, for example, you can use `df.fillna()` or `df.dropna()` methods, that will replace missing values with a default value or drop rows, or explore sophisticated imputation methods from external libraries, like scikit-learn.',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'When applying pattern recognition to time series data, are there any specific considerations?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'As we are dealing with a temporal analysis on the data, considerations must include handling seasonality, trend decomposition, and selecting appropriate time series models. Techniques like differencing, moving averages, and seasonality decomposition can be applied. Python does provide some libraries like `statsmodels` and `prophet` that can help you address these considerations effectively.',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'When choosing a machine learning model for pattern recognition, how can I know which is the most suitable algorithm for my dataset?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"It depends on the patterns you seek and your data characteristics. Begin with simpler models like decision trees and progress to more complex ones if needed. To evaluate them, check metrics of accuracy, precision, recall and F1 score. Techniques like cross-validation and hyperparameter tuning help optimize model performance.\\n\\nPython's scikit-learn library provides a comprehensive suite of machine learning tools, making it easy to experiment with various algorithms and evaluate their performance on your specific dataset.\",\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [{'cell_position': 5,\n",
       "     'what': 'The code does not handle the case where the log file might be too large to fit into memory.',\n",
       "     'why': 'The user initially asked about parsing large log files, which implies that memory efficiency is a concern.',\n",
       "     'where': 'In the code snippet for reading and plotting the log file.',\n",
       "     'fix': 'Modify the code to process the log file in chunks, similar to the example provided in cell 2 for handling large files.'},\n",
       "    {'cell_position': 8,\n",
       "     'what': \"The code snippet uses placeholder column names 'feature1', 'feature2' without ensuring these columns exist in the user's data.\",\n",
       "     'why': \"The user's log data might not have these columns, leading to a KeyError.\",\n",
       "     'where': 'In the IsolationForest fit_predict method call.',\n",
       "     'fix': 'Ask the user for the specific column names to use or provide a generic method to select numerical columns from the DataFrame.'},\n",
       "    {'cell_position': 11,\n",
       "     'what': \"The code snippet assumes that the DataFrame 'df' is suitable for association rule mining without preprocessing.\",\n",
       "     'why': 'Association rule mining typically requires a DataFrame of boolean values, not raw log data.',\n",
       "     'where': 'In the apriori function call.',\n",
       "     'fix': 'Include preprocessing steps to convert the log data into a suitable format for association rule mining, such as one-hot encoding.'},\n",
       "    {'cell_position': 14,\n",
       "     'what': \"The code snippet uses placeholder column names 'feature1', 'feature2' without ensuring these columns exist in the user's data.\",\n",
       "     'why': \"The user's log data might not have these columns, leading to a KeyError.\",\n",
       "     'where': 'In the KMeans fit_predict method call.',\n",
       "     'fix': 'Ask the user for the specific column names to use or provide a generic method to select numerical columns from the DataFrame.'}],\n",
       "   'could_have_been_better_issues': [{'cell_position': 5,\n",
       "     'what': \"The 'date_parser' parameter in 'read_csv' is set to 'pd.to_datetime' which is unnecessary.\",\n",
       "     'why': \"Pandas automatically parses columns specified in 'parse_dates' as datetime objects, so explicitly setting 'date_parser' to 'pd.to_datetime' is redundant.\",\n",
       "     'where': \"In the 'read_csv' function call.\",\n",
       "     'fix': \"Remove the 'date_parser' parameter from the 'read_csv' call.\"},\n",
       "    {'cell_position': 5,\n",
       "     'what': \"The code does not specify the 'header' parameter when reading the log file.\",\n",
       "     'why': 'If the log file has a header row, it should be handled appropriately to avoid incorrect data interpretation.',\n",
       "     'where': \"In the 'read_csv' function call.\",\n",
       "     'fix': \"Add the 'header' parameter with the appropriate value based on the log file structure.\"}],\n",
       "   'scoring_explanation': \"The code provided by the Assistant is generally correct and follows good practices, but there are some medium severity issues related to the handling of large files and assumptions about the user's data structure. These issues could lead to errors or inefficient processing of the log file. The could-have-been-better issues are minor and would not significantly impact the functionality but would improve the code quality. The conversation is complete, and the user's requests are satisfied with the provided code, albeit with some necessary adjustments.\",\n",
       "   'score': 3},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n**Cell 5**: The code does not handle the case where the log file might be too large to fit into memory.\\n- **Why**: The user initially asked about parsing large log files, which implies that memory efficiency is a concern.\\n- **Where**: In the code snippet for reading and plotting the log file.\\n- **Fix**: Modify the code to process the log file in chunks, similar to the example provided in cell 2 for handling large files.\\n\\n**Cell 8**: The code snippet uses placeholder column names 'feature1', 'feature2' without ensuring these columns exist in the user's data.\\n- **Why**: The user's log data might not have these columns, leading to a KeyError.\\n- **Where**: In the IsolationForest fit_predict method call.\\n- **Fix**: Ask the user for the specific column names to use or provide a generic method to select numerical columns from the DataFrame.\\n\\n**Cell 11**: The code snippet assumes that the DataFrame 'df' is suitable for association rule mining without preprocessing.\\n- **Why**: Association rule mining typically requires a DataFrame of boolean values, not raw log data.\\n- **Where**: In the apriori function call.\\n- **Fix**: Include preprocessing steps to convert the log data into a suitable format for association rule mining, such as one-hot encoding.\\n\\n**Cell 14**: The code snippet uses placeholder column names 'feature1', 'feature2' without ensuring these columns exist in the user's data.\\n- **Why**: The user's log data might not have these columns, leading to a KeyError.\\n- **Where**: In the KMeans fit_predict method call.\\n- **Fix**: Ask the user for the specific column names to use or provide a generic method to select numerical columns from the DataFrame.\\n\\n# Scoring Explanation\\nThe code provided by the Assistant is generally correct and follows good practices, but there are some medium severity issues related to the handling of large files and assumptions about the user's data structure. These issues could lead to errors or inefficient processing of the log file. The could-have-been-better issues are minor and would not significantly impact the functionality but would improve the code quality. The conversation is complete, and the user's requests are satisfied with the provided code, albeit with some necessary adjustments.\\n\\n# Score: 3\\n\\n\"},\n",
       " {'id': '1Unbsf2xICxBcqMFzYBbyS9NW4kVtr7Os',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1Unbsf2xICxBcqMFzYBbyS9NW4kVtr7Os',\n",
       "  'revision_id': None,\n",
       "  'metadata': {'topic': 'debugging_and_tracing', 'target_turns': '1-4'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': \"Hi, I'm a Financial Analyst with some expertise in machine learning, and I'm preparing for a crucial interview. I'm working on a scikit-learn model to predict stock price movements but encountering some difficulties. Can we talk through some debugging strategies?\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Certainly! It's great that you're tackling such intricate work. Troubleshooting a model can involve several steps. Let's start with the basics: have you checked for any inconsistencies in your data, such as missing values, outliers, or incorrectly scaled features? These are common culprits that can skew model performance.\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': \"Indeed, I've preprocessed the data, handling missing values and outliers, but I havenâ€™t done feature scaling yet. Could that be the issue? And how would I go about implementing it?\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Feature scaling can significantly impact the algorithm's ability to learn effectively, especially for algorithms sensitive to the scale of the data like SVMs or k-means clustering. In scikit-learn, you could use `StandardScaler` for this purpose:\\n\\n```python\\nfrom sklearn.preprocessing import StandardScaler\\n\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n# Then, use X_scaled to fit your predictive model\\n```\\n\\nBy applying scaling, you ensure that features contribute equally to the prediction process, allowing the model to perform better, especially if you're using gradient descent for optimization. Just be sure to fit the scaler on the training data only, to avoid data leakage.\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Okay, Iâ€™ve implemented scaling now. The model is performing better, but itâ€™s still not as accurate as I need it to be for the interview. Any suggestions for further tuning?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Improving model accuracy further can be a nuanced process. If you've not already applied it, consider hyperparameter tuning. Tools like `GridSearchCV` or `RandomizedSearchCV` can help you systematically explore a range of values and find the optimal settings for your predictive model.\\n\\nHere's an example with `RandomizedSearchCV`:\\n\\n```python\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestRegressor\\n\\n# Define your parameter grid\\nparam_grid = {\\n    'n_estimators': [100, 200, 300],\\n    'max_features': ['auto', 'sqrt', 'log2'],\\n    'max_depth': [None, 10, 20, 30]\\n}\\n\\n# Setup the grid search\\nrandom_search = RandomizedSearchCV(RandomForestRegressor(), param_grid, n_iter=50, cv=5, random_state=42)\\nrandom_search.fit(X_scaled, y)\\n\\n# Use the best estimator to make predictions\\nbest_model = random_search.best_estimator_\\n```\\n\\nRemember to explore the parameters that are most relevant to your specific model. What machine learning model are you using for your prediction?\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': \"I'm using a Gradient Boosting Regressor. Do the parameters you suggested still apply?\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Gradient Boosting Regressors have some unique parameters, but there's some overlap. For your model, you might want to explore `n_estimators`, `learning_rate`, and `subsample` among others. Here's how you might adjust the parameter grid for a gradient boosting model:\\n\\n```python\\nfrom sklearn.ensemble import GradientBoostingRegressor\\n\\n# Define the parameter grid specific to GradientBoostingRegressor\\nparam_grid = {\\n    'n_estimators': [100, 200, 300],\\n    'learning_rate': [0.01, 0.1, 0.2],\\n    'subsample': [0.9, 1.0],\\n    'max_depth': [3, 4, 5]\\n}\\n\\n# additional code stays the same for setup and fit\\n```\\n\\nStart with broader ranges and then narrow down based on your initial results. Using cross-validation as part of the grid search ensures that the modelâ€™s performance assessment is as robust as possible. How does that fit with the approach you were considering?\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': \"Thank you. I'll adjust the grid and run some more tests. I appreciate your help!\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"You're welcome! It's a pleasure to assist someone so engaged in the process. If you need further tuning or run into any more challenges, feel free to come back. Best of luck on your interview!\",\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [{'cell_position': 6,\n",
       "     'what': 'The `n_iter` parameter in `RandomizedSearchCV` is set to 50 without justification.',\n",
       "     'why': 'Using a high number of iterations without justification can lead to unnecessary computation time, especially when the parameter grid is large.',\n",
       "     'where': 'In the `RandomizedSearchCV` instantiation.',\n",
       "     'fix': 'Justify the choice of `n_iter` or reduce it to a more reasonable number considering the size of the parameter grid and computational constraints.'}],\n",
       "   'could_have_been_better_issues': [{'cell_position': 4,\n",
       "     'what': 'The code snippet lacks context, such as where `X` is coming from.',\n",
       "     'why': \"For a user who might not be familiar with the codebase, it's important to clarify the source of variables used in the example.\",\n",
       "     'where': 'In the code snippet provided for feature scaling.',\n",
       "     'fix': \"Add a comment before the code snippet explaining that `X` should be the features from the user's dataset.\"},\n",
       "    {'cell_position': 6,\n",
       "     'what': 'The code snippet does not show the use of `y` which is the target variable.',\n",
       "     'why': 'The user might not know what `y` represents in the context of the code.',\n",
       "     'where': 'In the `RandomizedSearchCV` fit method call.',\n",
       "     'fix': \"Add a comment before the code snippet explaining that `y` should be the target variable from the user's dataset.\"},\n",
       "    {'cell_position': 8,\n",
       "     'what': 'The code snippet is incomplete as it does not show the setup and fit process for `RandomizedSearchCV`.',\n",
       "     'why': 'The user is left to assume that the setup and fit process is the same as in the previous example, which might not be clear to all users.',\n",
       "     'where': 'In the code snippet provided for adjusting the parameter grid.',\n",
       "     'fix': 'Include the full example with the setup and fit process for `RandomizedSearchCV`, or explicitly state that the user should refer to the previous example.'}],\n",
       "   'scoring_explanation': \"The conversation is focused on providing guidance for debugging a scikit-learn model. The code provided by the Assistant is correct and follows best practices, such as the use of `StandardScaler` for feature scaling and `RandomizedSearchCV` for hyperparameter tuning. The code is also readable and consistent with the Assistant's programming identity. However, there is a medium severity issue with the potential overuse of iterations in `RandomizedSearchCV` without justification, which could lead to unnecessary computation. Additionally, there are minor issues with the lack of context for the code snippets and incomplete examples, which could have been more informative for the user. Overall, the conversation is useful and likely to satisfy the user's request for debugging strategies.\",\n",
       "   'score': 4},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n**Cell 6**: The `n_iter` parameter in `RandomizedSearchCV` is set to 50 without justification.\\n- **Why**: Using a high number of iterations without justification can lead to unnecessary computation time, especially when the parameter grid is large.\\n- **Where**: In the `RandomizedSearchCV` instantiation.\\n- **Fix**: Justify the choice of `n_iter` or reduce it to a more reasonable number considering the size of the parameter grid and computational constraints.\\n\\n# Scoring Explanation\\nThe conversation is focused on providing guidance for debugging a scikit-learn model. The code provided by the Assistant is correct and follows best practices, such as the use of `StandardScaler` for feature scaling and `RandomizedSearchCV` for hyperparameter tuning. The code is also readable and consistent with the Assistant's programming identity. However, there is a medium severity issue with the potential overuse of iterations in `RandomizedSearchCV` without justification, which could lead to unnecessary computation. Additionally, there are minor issues with the lack of context for the code snippets and incomplete examples, which could have been more informative for the user. Overall, the conversation is useful and likely to satisfy the user's request for debugging strategies.\\n\\n# Score: 4\\n\\n\"},\n",
       " {'id': '1KtSOMVTE5kj8VuId-zm-y_TZVVMQwYwZ',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1KtSOMVTE5kj8VuId-zm-y_TZVVMQwYwZ',\n",
       "  'revision_id': None,\n",
       "  'metadata': {'topic': 'debugging_and_tracing', 'target_turns': '1-4'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': \"Hi there, I'm prepping for a Smart City Planner interview. Part of my role will involve building a predictive maintenance system for urban infrastructure. Iâ€™m planning to use scikit-learn to develop the model but I'm getting stuck on fine-tuning. Any tips?\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Sure thing! Fine-tuning a machine learning model can be quite nuanced. Can you tell me what kind of performance metrics you're looking at and what specifically you're seeing with your model's output? Any details on the dataset youâ€™re using will also be helpful.\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': \"I'm using the dataset that includes historical utility data like usage patterns, failure incidents, and environmental impacts. My model's accuracy appears lower than the industry standard. Here's the basic structure Iâ€™ve been working with:\\n\\n```python\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Split the dataset\\nX_train, X_test, y_train, y_test = train_test_split(feature_data, labels, test_size=0.2)\\n\\n# Initialize the model\\nmodel = RandomForestClassifier()\\n\\n# Train the model\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions\\npredictions = model.predict(X_test)\\n\\n# Evaluate the model\\nprint(accuracy_score(y_test, predictions))\\n```\\n\\nI suspect I may need to dive deeper into hyperparameter tuning or modifying my feature set.\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"That's a good start. Indeed, hyperparameter tuning is essential. Considering your dataset, tuning parameters of `RandomForestClassifier` like `n_estimators`, `max_features`, and `max_depth` could lead to better results. Also, feature engineering plays a critical role in predictive maintenance; make sure to include domain-specific knowledge into your features.\\n\\nTo go about systematically, you could employ `GridSearchCV` or `RandomizedSearchCV` for hyperparameter optimization. Here's how you could incorporate cross-validation and hyperparameter tuning:\\n\\n```python\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Define the parameter grid\\nparam_grid = {\\n    'n_estimators': [100, 200, 300],\\n    'max_features': ['auto', 'sqrt', 'log2'],\\n    'max_depth': [4, 6, 8]\\n}\\n\\n# Initialize GridSearchCV\\ngrid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\\n\\n# Perform the grid search and fit the model\\ngrid_search.fit(X_train, y_train)\\n\\n# Get the best model\\nbest_model = grid_search.best_estimator_\\n\\n# Make predictions\\nbest_predictions = best_model.predict(X_test)\\n\\n# Evaluate the best model\\nprint(accuracy_score(y_test, best_predictions))\\n```\\nThis snippet begins hyperparameter tuning with `GridSearchCV`, a powerful method that evaluates all the combinations of parameters in your grid.\\n\\nIntegrating your domain expertise to prioritize which features are engineered and which hyperparameters are emphasized is advised. Does this align with your understanding of your dataset and the model's application?\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Yes, it does align well. My only concern is that GridSearchCV might be time-consuming given the exhaustive search it performs. Is there an alternative that could lead to a good-enough model but in less time?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"\\n**Assistant**\\n\\nYou're correct that GridSearchCV can be computationally expensive. A more time-efficient alternative is `RandomizedSearchCV`, which samples a fixed number of parameter combinations from the specified distributions. This approach can often find a good enough model much faster.\\n\\nHereâ€™s how you might set up `RandomizedSearchCV`:\\n\\n```python\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom scipy.stats import randint\\n\\n# Define the parameter distributions\\nparam_distributions = {\\n    'n_estimators': randint(100, 500),\\n    'max_features': ['auto', 'sqrt', 'log2'],\\n    'max_depth': randint(4, 10)\\n}\\n\\n# Initialize RandomizedSearchCV\\nrandom_search = RandomizedSearchCV(estimator=model,\\n                                   param_distributions=param_distributions,\\n                                   n_iter=10, cv=5, random_state=42)\\n\\n# Perform the random search and fit the model\\nrandom_search.fit(X_train, y_train)\\n\\n# Get the best model\\nbest_random_model = random_search.best_estimator_\\n\\n# Make predictions\\nbest_random_predictions = best_random_model.predict(X_test)\\n\\n# Evaluate the best random model\\nprint(accuracy_score(y_test, best_random_predictions))\\n```\\n\\nThis code will try out ten different combinations from your distribution and pick the best one, striking a balance between performance and time. How does this methodology fit into your workflow?\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'That seems like a practical approach to get me started. However, once I find a promising model configuration, is there a way to refine it further?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Certainly! Once you've narrowed down the hyperparameter space using `RandomizedSearchCV`, you can hone in on the best parameters by running a more focused `GridSearchCV` around those values. Here's what you can do:\\n\\n```python\\n# Assume these are the promising ranges found from RandomizedSearchCV\\nn_estimators_range = [best_random_model.n_estimators - 50, best_random_model.n_estimators, best_random_model.n_estimators + 50]\\nmax_depth_range = [best_random_model.max_depth - 2, best_random_model.max_depth, best_random_model.max_depth + 2]\\nmax_features_range = [best_random_model.max_features]\\n\\n# Define a new grid based on the output of RandomizedSearchCV\\nrefined_param_grid = {\\n    'n_estimators': n_estimators_range,\\n    'max_features': max_features_range,\\n    'max_depth': max_depth_range\\n}\\n\\n# Initialize a new GridSearchCV with the refined grid\\nrefined_grid_search = GridSearchCV(estimator=model, param_grid=refined_param_grid, cv=5)\\n\\n# Perform the grid search and fit the model\\nrefined_grid_search.fit(X_train, y_train)\\n\\n# Get the best refined model\\nbest_refined_model = refined_grid_search.best_estimator_\\n\\n# Make predictions\\nrefined_predictions = best_refined_model.predict(X_test)\\n\\n# Evaluate the best refined model\\nprint(accuracy_score(y_test, refined_predictions))\\n```\\n\\nBy iterating between randomized and grid searches, you can efficiently narrow your hyperparameter search space and then conduct a thorough exploration within that refined range. This two-step approach allows you to be thorough yet efficient with your timeâ€”a perfect discussion point for your interview.\",\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [{'cell_position': 4,\n",
       "     'what': 'The code snippet does not handle the case where `feature_data` and `labels` are undefined.',\n",
       "     'why': \"The code assumes that `feature_data` and `labels` are predefined variables without ensuring their existence or loading them from a data source, which could lead to a `NameError` if they are not defined in the user's environment.\",\n",
       "     'where': 'In the code snippet where `train_test_split(feature_data, labels, test_size=0.2)` is called.',\n",
       "     'fix': 'Include code to load the dataset or check if `feature_data` and `labels` are defined before using them.'},\n",
       "    {'cell_position': 6,\n",
       "     'what': 'The code snippet uses a fixed `random_state` without explanation.',\n",
       "     'why': 'Setting a `random_state` ensures reproducibility but the choice of the number should be justified or at least mentioned to the user.',\n",
       "     'where': 'In the `RandomizedSearchCV` initialization: `random_state=42`.',\n",
       "     'fix': 'Explain the purpose of setting a `random_state` and why the number 42 was chosen, or allow the user to set their own `random_state`.'}],\n",
       "   'could_have_been_better_issues': [{'cell_position': 4,\n",
       "     'what': 'The code snippet does not include an import statement for `RandomForestClassifier`.',\n",
       "     'why': \"While the user provided a code snippet with the import statement, the Assistant's code snippet should be self-contained and include all necessary imports for clarity.\",\n",
       "     'where': 'In the code snippet provided for hyperparameter tuning with `GridSearchCV`.',\n",
       "     'fix': 'Add the line `from sklearn.ensemble import RandomForestClassifier` at the beginning of the code snippet.'},\n",
       "    {'cell_position': 8,\n",
       "     'what': 'The code snippet assumes the existence of `best_random_model` without showing how it is obtained.',\n",
       "     'why': 'The code snippet uses `best_random_model` to define the ranges for the refined grid search, but it does not show the previous step of obtaining this model from `RandomizedSearchCV`, which might confuse the user.',\n",
       "     'where': 'In the code snippet where `n_estimators_range`, `max_depth_range`, and `max_features_range` are defined based on `best_random_model`.',\n",
       "     'fix': 'Include a comment or a brief explanation that `best_random_model` is the result of the previous `RandomizedSearchCV` step.'}],\n",
       "   'scoring_explanation': \"The code provided by the Assistant is correct and follows best practices for hyperparameter tuning using `GridSearchCV` and `RandomizedSearchCV`. The code is readable and consistent with the Assistant's programming identity. However, there are medium severity issues related to the assumptions of predefined variables and the use of a fixed `random_state`. These issues could lead to errors if the user's environment is not set up as expected by the Assistant's code. Additionally, there are minor issues with the code snippets not being entirely self-contained and lacking some context, which could be improved for better clarity. The conversation is complete, and the user's request for understanding hyperparameter tuning alternatives and further refinement is satisfied.\",\n",
       "   'score': 4},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n**Cell 4**: The code snippet does not handle the case where `feature_data` and `labels` are undefined.\\n- **Why**: The code assumes that `feature_data` and `labels` are predefined variables without ensuring their existence or loading them from a data source, which could lead to a `NameError` if they are not defined in the user's environment.\\n- **Where**: In the code snippet where `train_test_split(feature_data, labels, test_size=0.2)` is called.\\n- **Fix**: Include code to load the dataset or check if `feature_data` and `labels` are defined before using them.\\n\\n**Cell 6**: The code snippet uses a fixed `random_state` without explanation.\\n- **Why**: Setting a `random_state` ensures reproducibility but the choice of the number should be justified or at least mentioned to the user.\\n- **Where**: In the `RandomizedSearchCV` initialization: `random_state=42`.\\n- **Fix**: Explain the purpose of setting a `random_state` and why the number 42 was chosen, or allow the user to set their own `random_state`.\\n\\n# Scoring Explanation\\nThe code provided by the Assistant is correct and follows best practices for hyperparameter tuning using `GridSearchCV` and `RandomizedSearchCV`. The code is readable and consistent with the Assistant's programming identity. However, there are medium severity issues related to the assumptions of predefined variables and the use of a fixed `random_state`. These issues could lead to errors if the user's environment is not set up as expected by the Assistant's code. Additionally, there are minor issues with the code snippets not being entirely self-contained and lacking some context, which could be improved for better clarity. The conversation is complete, and the user's request for understanding hyperparameter tuning alternatives and further refinement is satisfied.\\n\\n# Score: 4\\n\\n\"},\n",
       " {'id': '1_lUJ5N3a8gX4pz2AEZ1LHhlLxKc-RsRG',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1_lUJ5N3a8gX4pz2AEZ1LHhlLxKc-RsRG',\n",
       "  'revision_id': '0BxmKQQ91GHhcVnoxR28rOGVVdlFvQVQ3bndDTVJwTHUweGY4PQ',\n",
       "  'metadata': {'topic': 'debugging_and_tracing', 'type': 'query'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': \"how would you use Python's debugging and tracing tools to diagnose and fix an intermittent issue.\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'Diagnosing and fixing intermittent bugs in a Python project, especially those that might be due to race conditions or resource unavailability, requires a systematic approach using various debugging and tracing tools.\\n\\n1. Start by running in debug mode, check environmental consistency\\n2. Analyze patterns, logging, code reviews',\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [],\n",
       "   'could_have_been_better_issues': [],\n",
       "   'scoring_explanation': \"The conversation provided does not contain any code generated by the AI Assistant. The user asked about using Python's debugging and tracing tools, and the Assistant provided a textual response with general steps to diagnose and fix an intermittent issue. Since there is no code to evaluate, the criteria for code correctness, efficiency, best practices, readability, style consistency, and purpose cannot be applied. Therefore, the score defaults to null, indicating the absence of code to review.\",\n",
       "   'score': None},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n# Scoring Explanation\\nThe conversation provided does not contain any code generated by the AI Assistant. The user asked about using Python's debugging and tracing tools, and the Assistant provided a textual response with general steps to diagnose and fix an intermittent issue. Since there is no code to evaluate, the criteria for code correctness, efficiency, best practices, readability, style consistency, and purpose cannot be applied. Therefore, the score defaults to null, indicating the absence of code to review.\\n\\n# Score: None\\n\\n\"},\n",
       " {'id': '1JUY9363HPsn5ChuweH_i31EzSsJPzSwX',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1JUY9363HPsn5ChuweH_i31EzSsJPzSwX',\n",
       "  'revision_id': '0BxmKQQ91GHhcN3ViTitrMVh2Vi82V3l6a2tpaGFWWnBLYlhZPQ',\n",
       "  'metadata': {'topic': 'debugging_and_tracing', 'type': 'query'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': 'Hi, I am getting error running the code: The generated image exceeds the limit. How to solve it?\\n```python\\nPaddleHub2.4.0, PaddlePaddle2.5.2\\nSystem environment: Windows\\npython version: 3.9.18\\nError report: In the prediction code example, an error is reported after running images = module.generate_image(text_prompts=text_prompts, style=\\'oil painting\\', output_dir=\\'./ernie_vilg_out/\\')\\nTraceback (most recent call last):\\nFile \"\", line 1, in\\nFile \"C:\\\\Users\\\\k\\\\anaconda3\\\\envs\\\\wm\\\\lib\\\\site-packages\\\\paddlehub\\\\compat\\\\paddle_utils.py\", line 221, in runner\\nreturn func(*args, **kwargs)\\nFile \"C:\\\\Users\\\\k.paddlehub\\\\modules\\\\ernie_vilg\\\\module.py\", line 121, in generate_image\\nraise RuntimeError(res[\\'msg\\'])\\nRuntimeError: generated image exceeds limit\\n\\n```',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'Could you provide more information about the script and anaconda environment?',\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [],\n",
       "   'could_have_been_better_issues': [],\n",
       "   'scoring_explanation': 'The conversation provided does not include any code generated by the AI Assistant. The user has presented an issue with their code, and the Assistant has only asked for more information to better understand the problem. Since there is no code to evaluate, the criteria for code correctness, efficiency, best practices, readability, style consistency, and purpose cannot be applied. Therefore, the conversation cannot be scored based on the code quality rubric.',\n",
       "   'score': None},\n",
       "  'formatted_review': '# Critical Severity Issues\\n# Medium Severity Issues\\n# Scoring Explanation\\nThe conversation provided does not include any code generated by the AI Assistant. The user has presented an issue with their code, and the Assistant has only asked for more information to better understand the problem. Since there is no code to evaluate, the criteria for code correctness, efficiency, best practices, readability, style consistency, and purpose cannot be applied. Therefore, the conversation cannot be scored based on the code quality rubric.\\n\\n# Score: None\\n\\n'},\n",
       " {'id': '1kL_7R8kTnbT0nDuuVweaHMszel7ITPhO',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1kL_7R8kTnbT0nDuuVweaHMszel7ITPhO',\n",
       "  'revision_id': '0BxmKQQ91GHhcUXIrSWdkaFM3eTBjNkVkei9WMmhZY0EycSs4PQ',\n",
       "  'metadata': {'topic': 'debugging_and_tracing', 'type': 'query'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': \"Hi, I am getting following error\\n\\n**No module named 'backports' after python upgrade #8711**\\n\\nWe've upgraded the python version from 3.8 to 3.11. After the upgrade, the celery beat is not starting anymore.\\n\\nWhen running celery --app app beat --loglevel WARNING the process crashes with the following error message:\\nModuleNotFoundError: No module named 'backports'\\n\\nThe same issue is reported/asked at [stackoverflow](https://stackoverflow.com/q/77416290/10992051)\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'Can you provide more details about Python/Celery Environment?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Here are python environment details:\\n*   Minimal Python Version: 3.11.7\\n*   Minimal Celery Version: 5.3.6\\n*   Minimal Kombu Version: 5.3.4\\n\\nHere are Celery Environment detail:\\n\\n```\\nsoftware -> celery:5.3.6 (emerald-rush) kombu:5.3.4 py:3.12.1\\n            billiard:4.2.0 py-amqp:5.2.0\\nplatform -> system:Linux arch:64bit, ELF\\n            kernel version:5.4.0-167-generic imp:CPython\\nloader   -> celery.loaders.default.Loader\\nsettings -> transport:amqp results:disabled\\n\\ndeprecated_settings: None\\n```\\n\\nHere is stacktrace from above stackoverflow:\\n```\\ncelery beat v5.3.4 (emerald-rush) is starting.\\n__    -    ... __   -        _\\nLocalTime -> 2023-11-03 10:48:13\\nConfiguration ->\\n    . broker -> redis://redis:6379/0\\n    . loader -> celery.loaders.app.AppLoader\\n    . scheduler -> celery.beat.PersistentScheduler\\n    . db -> celerybeat-schedule\\n    . logfile -> [stderr]@%DEBUG\\n    . maxinterval -> 5.00 minutes (300s)\\n[2023-11-03 10:48:13,939: DEBUG/MainProcess] Setting default socket timeout to 30\\n[2023-11-03 10:48:13,940: INFO/MainProcess] beat: Starting...\\n[2023-11-03 10:48:13,945: CRITICAL/MainProcess] beat raised exception <class \\'ModuleNotFoundError\\'>: ModuleNotFoundError(\"No module named \\'backports\\'\")\\nTraceback (most recent call last):\\n  File \"/usr/local/lib/python3.10/shelve.py\", line 111, in __getitem__\\n    value = self.cache[key]\\nKeyError: \\'entries\\'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/lib/python3.10/site-packages/celery/apps/beat.py\", line 113, in start_scheduler\\n    service.start()\\n  File \"/usr/local/lib/python3.10/site-packages/celery/beat.py\", line 634, in start\\n    humanize_seconds(self.scheduler.max_interval))\\n  File \"/usr/local/lib/python3.10/site-packages/kombu/utils/objects.py\", line 31, in __get__\\n    return super().__get__(instance, owner)\\n  File \"/usr/local/lib/python3.10/functools.py\", line 981, in __get__\\n    val = self.func(instance)\\n  File \"/usr/local/lib/python3.10/site-packages/celery/beat.py\", line 677, in scheduler\\n    return self.get_scheduler()\\n  File \"/usr/local/lib/python3.10/site-packages/celery/beat.py\", line 668, in get_scheduler\\n    return symbol_by_name(self.scheduler_cls, aliases=aliases)(\\n  File \"/usr/local/lib/python3.10/site-packages/celery/beat.py\", line 513, in __init__\\n    super().__init__(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/site-packages/celery/beat.py\", line 264, in __init__\\n    self.setup_schedule()\\n  File \"/usr/local/lib/python3.10/site-packages/celery/beat.py\", line 541, in setup_schedule\\n    self._create_schedule()\\n  File \"/usr/local/lib/python3.10/site-packages/celery/beat.py\", line 570, in _create_schedule\\n    self._store[\\'entries\\']\\n  File \"/usr/local/lib/python3.10/shelve.py\", line 114, in __getitem__\\n    value = Unpickler(f).load()\\nModuleNotFoundError: No module named \\'backports\\'\\n\\n```',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'Try removing the task scheduler DB and try executing celery beat again.',\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [],\n",
       "   'could_have_been_better_issues': [],\n",
       "   'scoring_explanation': \"The Assistant's response does not contain any code, therefore, there is no code to evaluate in terms of correctness, efficiency, best practices, readability, consistency, or purpose. The Assistant's suggestion to remove the task scheduler DB is a valid troubleshooting step for the issue described by the user, but since it is not a code snippet, it falls outside the scope of this review. The conversation is focused on diagnosing a problem rather than writing or refining code.\",\n",
       "   'score': None},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n# Scoring Explanation\\nThe Assistant's response does not contain any code, therefore, there is no code to evaluate in terms of correctness, efficiency, best practices, readability, consistency, or purpose. The Assistant's suggestion to remove the task scheduler DB is a valid troubleshooting step for the issue described by the user, but since it is not a code snippet, it falls outside the scope of this review. The conversation is focused on diagnosing a problem rather than writing or refining code.\\n\\n# Score: None\\n\\n\"},\n",
       " {'id': '1FIo_t-nNB41OVE4BqsfHC8EeMKcB3hVd',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1FIo_t-nNB41OVE4BqsfHC8EeMKcB3hVd',\n",
       "  'revision_id': '0BxmKQQ91GHhcSW81WFNNVHdYUjFHQmZsK25yQU9QdzZpeUlVPQ',\n",
       "  'metadata': {'topic': 'algorithms > by_data_structure > trees',\n",
       "   'type': 'modification',\n",
       "   'target_turns': '4-8'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': \"Can you help me modify my Python code to print the level order traversal of a binary tree in reverse? Here's what I have for the regular level order: ```def level_order_traversal(root): queue = [root] while queue: node = queue.pop(0) print(node.value) if node.left: queue.append(node.left) if node.right: queue.append(node.right)```\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'The code for reverse level order traversal is below\\n```python\\ndef rev_level_order_traversal(root):\\n  # Define the Deque\\n  deq = deque()\\n  # append root to deq\\n  deq.append(root)\\n  while deq:\\n    # pop from left of thedeque\\n    node = deq.popleft(0)\\n\\n    print(node.value)\\n    \"\"\"\\n    First append the right side of tree to deque\\n    then append the left side of tree\\n    \"\"\"\\n    if node.right:\\n      deq.append(node.right)\\n\\n    if node.left:\\n      deq.append(node.left)\\n```',\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [{'cell_position': 2,\n",
       "     'what': 'The code does not perform a reverse level order traversal.',\n",
       "     'why': 'The code provided performs a regular level order traversal from right to left, not a reverse level order traversal.',\n",
       "     'where': 'In the function `rev_level_order_traversal`.',\n",
       "     'fix': 'Implement a reverse level order traversal by using a queue for level order traversal and a stack to reverse the order.'}],\n",
       "   'medium_severity_issues': [{'cell_position': 2,\n",
       "     'what': 'Incorrect use of `popleft` method.',\n",
       "     'why': 'The `popleft` method is called with an argument, but it does not take any arguments.',\n",
       "     'where': 'In the line `node = deq.popleft(0)`.',\n",
       "     'fix': 'Change the line to `node = deq.popleft()`.'},\n",
       "    {'cell_position': 2,\n",
       "     'what': 'The `deque` class is used without being imported.',\n",
       "     'why': 'The code uses `deque` from the `collections` module without importing it, which will result in a `NameError`.',\n",
       "     'where': 'At the beginning of the function `rev_level_order_traversal`.',\n",
       "     'fix': 'Add the import statement `from collections import deque` at the beginning of the code.'}],\n",
       "   'could_have_been_better_issues': [{'cell_position': 2,\n",
       "     'what': 'The comment inside the triple quotes is not a docstring and is misplaced.',\n",
       "     'why': \"Triple quotes inside the function body are typically used for docstrings, and the comment is not providing information about the function's purpose, parameters, or return value.\",\n",
       "     'where': 'Inside the function `rev_level_order_traversal`, after the `print(node.value)` line.',\n",
       "     'fix': 'Move the comment outside of the triple quotes and use single-line comments with `#` for clarity.'}],\n",
       "   'scoring_explanation': \"The code provided in cell 2 does not satisfy the user's request for a reverse level order traversal, which is a critical issue. Additionally, there are medium severity issues with the incorrect use of `popleft` and the missing import statement for `deque`. The misplaced comment is a minor issue that affects readability. Due to these issues, the code is not correct, and the conversation does not end in user request full satisfaction, leading to a score of 1.\",\n",
       "   'score': 1},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n**Cell 2**: The code does not perform a reverse level order traversal.\\n- **Why**: The code provided performs a regular level order traversal from right to left, not a reverse level order traversal.\\n- **Where**: In the function `rev_level_order_traversal`.\\n- **Fix**: Implement a reverse level order traversal by using a queue for level order traversal and a stack to reverse the order.\\n\\n# Medium Severity Issues\\n**Cell 2**: Incorrect use of `popleft` method.\\n- **Why**: The `popleft` method is called with an argument, but it does not take any arguments.\\n- **Where**: In the line `node = deq.popleft(0)`.\\n- **Fix**: Change the line to `node = deq.popleft()`.\\n\\n**Cell 2**: The `deque` class is used without being imported.\\n- **Why**: The code uses `deque` from the `collections` module without importing it, which will result in a `NameError`.\\n- **Where**: At the beginning of the function `rev_level_order_traversal`.\\n- **Fix**: Add the import statement `from collections import deque` at the beginning of the code.\\n\\n# Scoring Explanation\\nThe code provided in cell 2 does not satisfy the user's request for a reverse level order traversal, which is a critical issue. Additionally, there are medium severity issues with the incorrect use of `popleft` and the missing import statement for `deque`. The misplaced comment is a minor issue that affects readability. Due to these issues, the code is not correct, and the conversation does not end in user request full satisfaction, leading to a score of 1.\\n\\n# Score: 1\\n\\n\"},\n",
       " {'id': '182EqzbvKd4W7-eEuAoRInPtWzMj9oVPl',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/182EqzbvKd4W7-eEuAoRInPtWzMj9oVPl',\n",
       "  'revision_id': '0BxmKQQ91GHhcam5WdFkrVFE0bkFQb2l2L1JOUzhrZGZ5Q1dRPQ',\n",
       "  'metadata': {'topic': 'debugging_and_tracing', 'type': 'query'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': 'Hello, I am trying to build and run a project using cookiecutter and I keep running into this error\\n\\n```python\\nTraceback (most recent call last):\\n  File \"/home/user/.local/bin/cookiecutter\", line 8, in <module>\\n    sys.exit(main())\\n             ^^^^^^\\n  File \"/home/user/.local/lib/python3.11/site-packages/click/core.py\", line 1157, in __call__\\n    return self.main(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/user/.local/lib/python3.11/site-packages/click/core.py\", line 1078, in main\\n    rv = self.invoke(ctx)\\n         ^^^^^^^^^^^^^^^^\\n  File \"/home/user/.local/lib/python3.11/site-packages/click/core.py\", line 1434, in invoke\\n    return ctx.invoke(self.callback, **ctx.params)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/user/.local/lib/python3.11/site-packages/click/core.py\", line 783, in invoke\\n    return __callback(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/user/.local/lib/python3.11/site-packages/cookiecutter/cli.py\", line 202, in main\\n    cookiecutter(\\n  File \"/home/user/.local/lib/python3.11/site-packages/cookiecutter/main.py\", line 184, in cookiecutter\\n    result = generate_files(\\n             ^^^^^^^^^^^^^^^\\n  File \"/home/user/.local/lib/python3.11/site-packages/cookiecutter/generate.py\", line 304, in generate_files\\n    template_dir = find_template(repo_dir)\\n                   ^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/user/.local/lib/python3.11/site-packages/cookiecutter/find.py\", line 24, in find_template\\n    raise NonTemplatedInputDirException\\ncookiecutter.exceptions.NonTemplatedInputDirException\\n```\\n\\nCan you please help me figure this out?\\n\\nThis is the command I am running\\n\\n`cookiecutter https://github.com/tiangolo/full-stack-fastapi-postgresql`',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'Hey there, sure. Let me see what I can find about this error.\\n\\nFrom what I can see, `cookiecutter` has been removed from the latest release of fastapi.\\n\\nThe related Github link for this is as follows:\\n\\nhttps://github.com/tiangolo/full-stack-fastapi-postgresql/pull/553',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Okay. Is there a workaround for this?  I mean an alternative to running\\n\\n`cookiecutter https://github.com/tiangolo/full-stack-fastapi-postgresql`\\n\\nI want to start the project from scratch since I made a few changes.',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'Sure, We can always checkout an older version of this project and run that so that we do not run into this issue. Please try and see if this fixes your issue:\\n\\n`cookie-cutter https://github.com/tiangolo/full-stack-fastapi-postgresql --checkout 30c722339b4fa6d4c2bd3deb7cca6fc3d9568f83`',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Thanks. This seems to have fixed the problem.',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'That is good!! Happy to have helped!',\n",
       "    'type': 'markdown'}],\n",
       "  'raw_review': {'critical_severity_issues': [],\n",
       "   'medium_severity_issues': [],\n",
       "   'could_have_been_better_issues': [{'cell_position': 4,\n",
       "     'what': 'Incorrect command provided',\n",
       "     'why': \"The command provided by the Assistant uses 'cookie-cutter' instead of 'cookiecutter'.\",\n",
       "     'where': 'In the command string.',\n",
       "     'fix': \"Correct the command to use 'cookiecutter' instead of 'cookie-cutter'.\"}],\n",
       "   'scoring_explanation': \"The conversation contains no code cells, but the Assistant provided a command in markdown that had a typo. The user did not report any issues with the command, indicating that the user's request was satisfied despite the typo. Therefore, the conversation is scored highly, but not perfect due to the minor issue that could have been better.\",\n",
       "   'score': 4},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n# Scoring Explanation\\nThe conversation contains no code cells, but the Assistant provided a command in markdown that had a typo. The user did not report any issues with the command, indicating that the user's request was satisfied despite the typo. Therefore, the conversation is scored highly, but not perfect due to the minor issue that could have been better.\\n\\n# Score: 4\\n\\n\"},\n",
       " {'id': '1yfP7u0DJjcZvthfDq-_GQcc343eTRMWM',\n",
       "  'colab_link': 'https://colab.research.google.com/drive/1yfP7u0DJjcZvthfDq-_GQcc343eTRMWM',\n",
       "  'revision_id': '0BxmKQQ91GHhcaDhndXZza1FySklWVGVkQldjcjRnbXdTUVJjPQ',\n",
       "  'metadata': {'topic': 'algorithms > by_topic > searching',\n",
       "   'type': 'modification',\n",
       "   'target_turns': '1-4'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': \"Please help me modify this Python code to implement the Fibonacci search technique for a sorted array. Here's what I have so far: ```def fibonacci_search(arr, x, n): fibM_minus_2 = 0 fibM_minus_1 = 1 fibM = fibM_minus_1 + fibM_minus_2 while (fibM < n): fibM_minus_2 = fibM_minus_1 fibM_minus_1 = fibM fibM = fibM_minus_1 + fibM_minus_2 # Continue the implementation here return -1```\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Hey buddy! Let me go through the modifications step by step with you:\\n\\nThis is your **original code**:\\n```python\\ndef fibonacci_search(arr, x, n):\\n    fibM_minus_2 = 0\\n    fibM_minus_1 = 1\\n    fibM = fibM_minus_1 + fibM_minus_2\\n\\n    while (fibM < n):\\n        fibM_minus_2 = fibM_minus_1\\n        fibM_minus_1 = fibM\\n        fibM = fibM_minus_1 + fibM_minus_2\\n    # Continue the implementation here\\n    return -1\\n```\\n\\nAnd I added the remaining implementation for **Fibonacci search** after your **while loop**. Replace the comment **'# Continue the implementation here'** with:\\n```python\\n    offset = -1\\n\\n    while (fibM > 1):\\n        i = min(offset + fibM_minus_2, n - 1)\\n\\n        if arr[i] < x:\\n            fibM, fibM_minus_1, fibM_minus_2 = (\\n                fibM_minus_1 - fibM_minus_2,\\n                fibM_minus_2,\\n                fibM_minus_1 - fibM_minus_2,\\n            )\\n            offset = i\\n\\n        elif arr[i] > x:\\n            fibM, fibM_minus_1, fibM_minus_2 = (\\n                fibM_minus_2,\\n                fibM_minus_1 - fibM_minus_2,\\n                fibM_minus_2 - fibM_minus_1,\\n            )\\n\\n        else:\\n            return i\\n\\n    if fibM_minus_1 and arr[offset + 1] == x:\\n        return offset + 1\\n```\\nHere, I:\\n- Introduced a new variable offset to keep track of the index.\\n- Used a while loop to perform the Fibonacci search.\\n- Checked conditions for updating the Fibonacci numbers and the offset.\\n- Returned the index if the element is found; otherwise, returned -1.\\n\\nCheck out the complete code below:\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'def fibonacci_search(arr, x, n):\\n    fibM_minus_2 = 0\\n    fibM_minus_1 = 1\\n    fibM = fibM_minus_1 + fibM_minus_2\\n\\n    while (fibM < n):\\n        fibM_minus_2 = fibM_minus_1\\n        fibM_minus_1 = fibM\\n        fibM = fibM_minus_1 + fibM_minus_2\\n\\n    offset = -1\\n\\n    while (fibM > 1):\\n        i = min(offset + fibM_minus_2, n - 1)\\n\\n        if arr[i] < x:\\n            fibM, fibM_minus_1, fibM_minus_2 = (\\n                fibM_minus_1 - fibM_minus_2,\\n                fibM_minus_2,\\n                fibM_minus_1 - fibM_minus_2,\\n            )\\n            offset = i\\n\\n        elif arr[i] > x:\\n            fibM, fibM_minus_1, fibM_minus_2 = (\\n                fibM_minus_2,\\n                fibM_minus_1 - fibM_minus_2,\\n                fibM_minus_2 - fibM_minus_1,\\n            )\\n\\n        else:\\n            return i\\n\\n    if fibM_minus_1 and arr[offset + 1] == x:\\n        return offset + 1\\n\\n    return -1',\n",
       "    'type': 'code'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Can you give me an example to test the Fibonacci search function?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'Hey, check out this example where we want to find the element **x = 85**. So, we call the `fibonacci_search` function with the **array**, the **element we wanna find (x)**, and the **length of the array (n)**. After that, we print out the **index** where the element is present. Easy peasy!',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': '# Example\\narr = [10, 22, 35, 40, 45, 50, 80, 82, 85, 90, 100]\\nx = 85\\nn = len(arr)\\n\\nresult = fibonacci_search(arr, x, n)\\nprint(result)',\n",
       "    'type': 'code'}],\n",
       "  'raw_review': {'critical_severity_issues': [{'cell_position': 3,\n",
       "     'what': \"Incorrect update of Fibonacci variables in the 'elif' branch.\",\n",
       "     'why': \"The code incorrectly updates the Fibonacci numbers in the 'elif arr[i] > x:' branch, which will lead to incorrect behavior of the search algorithm.\",\n",
       "     'where': \"In the 'elif' branch inside the second 'while' loop.\",\n",
       "     'fix': \"Change the line 'fibM_minus_2 - fibM_minus_1' to 'fibM_minus_1 - fibM_minus_2' to correctly update the Fibonacci numbers.\"}],\n",
       "   'medium_severity_issues': [{'cell_position': 3,\n",
       "     'what': 'The code does not handle the case where the array is empty.',\n",
       "     'why': 'If the array is empty, the function should return -1 immediately without performing any operations.',\n",
       "     'where': \"At the beginning of the 'fibonacci_search' function.\",\n",
       "     'fix': \"Add a condition to check if 'n == 0' at the beginning of the function and return -1 if true.\"}],\n",
       "   'could_have_been_better_issues': [{'cell_position': 3,\n",
       "     'what': \"The variable 'n' is redundant and can be derived from 'arr'.\",\n",
       "     'why': \"Passing the length of the array as an argument is unnecessary since it can be obtained from the array itself using 'len(arr)'.\",\n",
       "     'where': 'In the function signature and throughout the function.',\n",
       "     'fix': \"Remove the 'n' parameter from the function signature and replace its occurrences with 'len(arr)'.\"},\n",
       "    {'cell_position': 3,\n",
       "     'what': 'The code lacks comments explaining the logic of the Fibonacci search.',\n",
       "     'why': 'Comments would improve the readability and maintainability of the code by explaining the purpose of the code blocks and the logic behind the algorithm.',\n",
       "     'where': \"Throughout the 'fibonacci_search' function.\",\n",
       "     'fix': 'Add comments before each major block of code to explain the steps of the Fibonacci search algorithm.'}],\n",
       "   'scoring_explanation': \"The code in cell 3 has a critical issue with the incorrect update of Fibonacci variables, which can lead to incorrect search results. Additionally, there is a medium severity issue where the code does not handle the case of an empty array, which could cause an error if not checked. The code could also be improved by removing the redundant 'n' parameter and adding explanatory comments. Despite these issues, the code is mostly correct and follows good practices, but due to the critical issue, the score is significantly affected.\",\n",
       "   'score': 2},\n",
       "  'formatted_review': \"# Critical Severity Issues\\n**Cell 3**: Incorrect update of Fibonacci variables in the 'elif' branch.\\n- **Why**: The code incorrectly updates the Fibonacci numbers in the 'elif arr[i] > x:' branch, which will lead to incorrect behavior of the search algorithm.\\n- **Where**: In the 'elif' branch inside the second 'while' loop.\\n- **Fix**: Change the line 'fibM_minus_2 - fibM_minus_1' to 'fibM_minus_1 - fibM_minus_2' to correctly update the Fibonacci numbers.\\n\\n# Medium Severity Issues\\n**Cell 3**: The code does not handle the case where the array is empty.\\n- **Why**: If the array is empty, the function should return -1 immediately without performing any operations.\\n- **Where**: At the beginning of the 'fibonacci_search' function.\\n- **Fix**: Add a condition to check if 'n == 0' at the beginning of the function and return -1 if true.\\n\\n# Scoring Explanation\\nThe code in cell 3 has a critical issue with the incorrect update of Fibonacci variables, which can lead to incorrect search results. Additionally, there is a medium severity issue where the code does not handle the case of an empty array, which could cause an error if not checked. The code could also be improved by removing the redundant 'n' parameter and adding explanatory comments. Despite these issues, the code is mostly correct and follows good practices, but due to the critical issue, the score is significantly affected.\\n\\n# Score: 2\\n\\n\"}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_all_notebooks(parsed_notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Critical Severity Issues\n",
      "# Medium Severity Issues\n",
      "# Scoring Explanation\n",
      "The conversation provided does not contain any code generated by the AI Assistant for review. The user has presented an issue with their code, and the Assistant has only asked for more information to better understand the problem. Since there is no code from the Assistant to evaluate, the conversation cannot be scored based on the code quality criteria.\n",
      "\n",
      "# Score: 5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(notebooks_df['full_history_formatted_review'].loc[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import DATA_DIR\n",
    "\n",
    "def create_notebooks_dataframe(parsed_notebooks, selected_rows_df):\n",
    "    \"\"\"\n",
    "    Create a dataframe from parsed notebooks and selected rows with additional processing.\n",
    "\n",
    "    Args:\n",
    "    parsed_notebooks (list): List of parsed notebooks.\n",
    "    selected_rows_df (DataFrame): DataFrame of selected rows.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The resulting dataframe after merging and processing.\n",
    "    \"\"\"\n",
    "    notebooks_df = pd.DataFrame(parsed_notebooks)\n",
    "    notebooks_df['full_history_code_score'] = notebooks_df['raw_review'].apply(\n",
    "        lambda x: x.get('score') if x is not None else None\n",
    "    )\n",
    "    notebooks_df.rename(columns={'formatted_review': 'full_history_formatted_review'}, inplace=True)\n",
    "    notebooks_df = notebooks_df.merge(\n",
    "        selected_rows_df[['file_id', 'Code Quality', 'Language Quality', 'Feedback for the Trainer']],\n",
    "        left_on='id', right_on='file_id', how='left'\n",
    "    )\n",
    "    notebooks_df = notebooks_df[[\n",
    "        'colab_link', 'full_history_formatted_review', 'full_history_code_score',\n",
    "        'Code Quality', 'Language Quality', 'Feedback for the Trainer'\n",
    "    ]]\n",
    "    notebooks_df.rename(\n",
    "        columns={\n",
    "            'score': 'selected_rows_score',\n",
    "            'Code Quality': 'Human Code Quality',\n",
    "            'Language Quality': 'Human Language Quality',\n",
    "            'Feedback for the Trainer': 'Human Reviewer Feedback'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    notebooks_df['colab_link'] = notebooks_df['colab_link'].str.replace('?', '#')\n",
    "    return notebooks_df\n",
    "\n",
    "# Example usage:\n",
    "# new_df = create_notebooks_dataframe(parsed_notebooks, selected_rows_df)\n",
    "# new_df.to_csv(DATA_DIR + 'full_history_df_code_only.csv', index=False)\n",
    "# print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import DATA_DIR\n",
    "\n",
    "def create_notebooks_dataframe(parsed_notebooks, selected_rows_df):\n",
    "    \"\"\"\n",
    "    Create a dataframe from parsed notebooks and selected rows with additional processing.\n",
    "\n",
    "    Args:\n",
    "    parsed_notebooks (list): List of parsed notebooks.\n",
    "    selected_rows_df (DataFrame): DataFrame of selected rows.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The resulting dataframe after merging and processing.\n",
    "    \"\"\"\n",
    "    notebooks_df = pd.DataFrame(parsed_notebooks)\n",
    "    notebooks_df['full_history_code_score'] = notebooks_df['raw_review'].apply(\n",
    "        lambda x: x.get('score') if x is not None else None\n",
    "    )\n",
    "    notebooks_df.rename(columns={'formatted_review': 'full_history_formatted_review'}, inplace=True)\n",
    "    notebooks_df = notebooks_df.merge(\n",
    "        selected_rows_df[['file_id', 'Code Quality', 'Language Quality', 'Feedback for the Trainer']],\n",
    "        left_on='id', right_on='file_id', how='left'\n",
    "    )\n",
    "    notebooks_df = notebooks_df[[\n",
    "        'colab_link', 'full_history_formatted_review', 'full_history_code_score',\n",
    "        'Code Quality', 'Language Quality', 'Feedback for the Trainer'\n",
    "    ]]\n",
    "    notebooks_df.rename(\n",
    "        columns={\n",
    "            'score': 'selected_rows_score',\n",
    "            'Code Quality': 'Human Code Quality',\n",
    "            'Language Quality': 'Human Language Quality',\n",
    "            'Feedback for the Trainer': 'Human Reviewer Feedback'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    notebooks_df['colab_link'] = notebooks_df['colab_link'].str.replace('?', '#')\n",
    "    return notebooks_df\n",
    "\n",
    "# Example usage:\n",
    "# new_df = create_notebooks_dataframe(parsed_notebooks, selected_rows_df)\n",
    "# new_df.to_csv(DATA_DIR + 'full_history_df_code_only.csv', index=False)\n",
    "# print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_link</th>\n",
       "      <th>task_link_rev</th>\n",
       "      <th>full_history_formatted_review</th>\n",
       "      <th>full_history_code_score</th>\n",
       "      <th>Human Code Quality</th>\n",
       "      <th>Human Language Quality</th>\n",
       "      <th>Human Reviewer Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1UeXB6...</td>\n",
       "      <td>https://colab.research.google.com/drive/1UeXB6...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>- missing code example in first turn, a sample...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1qJPPq...</td>\n",
       "      <td>https://colab.research.google.com/drive/1qJPPq...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>--It's empty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1cP6qz...</td>\n",
       "      <td>https://colab.research.google.com/drive/1cP6qz...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-- No Explanation\\n-- No Headers\\n-- No Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1CPEz-...</td>\n",
       "      <td>https://colab.research.google.com/drive/1CPEz-...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/189Fne...</td>\n",
       "      <td>https://colab.research.google.com/drive/189Fne...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://colab.research.google.com/drive/1Unbsf...</td>\n",
       "      <td>https://colab.research.google.com/drive/1Unbsf...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://colab.research.google.com/drive/1KtSOM...</td>\n",
       "      <td>https://colab.research.google.com/drive/1KtSOM...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://colab.research.google.com/drive/1_lUJ5...</td>\n",
       "      <td>https://colab.research.google.com/drive/1_lUJ5...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-- assistant header is wrong it should be **As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://colab.research.google.com/drive/1JUY93...</td>\n",
       "      <td>https://colab.research.google.com/drive/1JUY93...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-- really low effort, I understand that someti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://colab.research.google.com/drive/1kL_7R...</td>\n",
       "      <td>https://colab.research.google.com/drive/1kL_7R...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-- The user question is clearly a copy and pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://colab.research.google.com/drive/1FIo_t...</td>\n",
       "      <td>https://colab.research.google.com/drive/1FIo_t...</td>\n",
       "      <td># Critical Severity Issues\\n**Cell 2**: The co...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>- Requirement was 4-8 turns only found 1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://colab.research.google.com/drive/182Eqz...</td>\n",
       "      <td>https://colab.research.google.com/drive/182Eqz...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>--Assistant does not have access to links \\nRa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://colab.research.google.com/drive/1yfP7u...</td>\n",
       "      <td>https://colab.research.google.com/drive/1yfP7u...</td>\n",
       "      <td># Critical Severity Issues\\n**Cell 3**: Incorr...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-- the code is incorrect. I think you copied t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           colab_link  \\\n",
       "0   https://colab.research.google.com/drive/1UeXB6...   \n",
       "1   https://colab.research.google.com/drive/1qJPPq...   \n",
       "2   https://colab.research.google.com/drive/1cP6qz...   \n",
       "3   https://colab.research.google.com/drive/1CPEz-...   \n",
       "4   https://colab.research.google.com/drive/189Fne...   \n",
       "5   https://colab.research.google.com/drive/1Unbsf...   \n",
       "6   https://colab.research.google.com/drive/1KtSOM...   \n",
       "7   https://colab.research.google.com/drive/1_lUJ5...   \n",
       "8   https://colab.research.google.com/drive/1JUY93...   \n",
       "9   https://colab.research.google.com/drive/1kL_7R...   \n",
       "10  https://colab.research.google.com/drive/1FIo_t...   \n",
       "11  https://colab.research.google.com/drive/182Eqz...   \n",
       "12  https://colab.research.google.com/drive/1yfP7u...   \n",
       "\n",
       "                                        task_link_rev  \\\n",
       "0   https://colab.research.google.com/drive/1UeXB6...   \n",
       "1   https://colab.research.google.com/drive/1qJPPq...   \n",
       "2   https://colab.research.google.com/drive/1cP6qz...   \n",
       "3   https://colab.research.google.com/drive/1CPEz-...   \n",
       "4   https://colab.research.google.com/drive/189Fne...   \n",
       "5   https://colab.research.google.com/drive/1Unbsf...   \n",
       "6   https://colab.research.google.com/drive/1KtSOM...   \n",
       "7   https://colab.research.google.com/drive/1_lUJ5...   \n",
       "8   https://colab.research.google.com/drive/1JUY93...   \n",
       "9   https://colab.research.google.com/drive/1kL_7R...   \n",
       "10  https://colab.research.google.com/drive/1FIo_t...   \n",
       "11  https://colab.research.google.com/drive/182Eqz...   \n",
       "12  https://colab.research.google.com/drive/1yfP7u...   \n",
       "\n",
       "                        full_history_formatted_review  \\\n",
       "0   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "1   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "2   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "3   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "4   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "5   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "6   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "7   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "8   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "9   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "10  # Critical Severity Issues\\n**Cell 2**: The co...   \n",
       "11  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "12  # Critical Severity Issues\\n**Cell 3**: Incorr...   \n",
       "\n",
       "    full_history_code_score Human Code Quality Human Language Quality  \\\n",
       "0                       4.0                  3                      3   \n",
       "1                       NaN                  1                      1   \n",
       "2                       3.0                  2                      1   \n",
       "3                       5.0                NaN                    NaN   \n",
       "4                       3.0                NaN                    NaN   \n",
       "5                       4.0                NaN                    NaN   \n",
       "6                       4.0                NaN                    NaN   \n",
       "7                       NaN                  1                      1   \n",
       "8                       NaN                  2                      2   \n",
       "9                       NaN                  1                      1   \n",
       "10                      1.0                  1                      1   \n",
       "11                      4.0                  2                      2   \n",
       "12                      2.0                  2                      5   \n",
       "\n",
       "                              Human Reviewer Feedback  \n",
       "0   - missing code example in first turn, a sample...  \n",
       "1                                       --It's empty.  \n",
       "2    -- No Explanation\\n-- No Headers\\n-- No Comments  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7   -- assistant header is wrong it should be **As...  \n",
       "8   -- really low effort, I understand that someti...  \n",
       "9   -- The user question is clearly a copy and pas...  \n",
       "10          - Requirement was 4-8 turns only found 1.  \n",
       "11  --Assistant does not have access to links \\nRa...  \n",
       "12  -- the code is incorrect. I think you copied t...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "notebooks_df = pd.DataFrame(parsed_notebooks)\n",
    "notebooks_df['full_history_code_score'] = notebooks_df['raw_review'].apply(lambda x: x.get('score') if x is not None else None)\n",
    "notebooks_df.rename(columns={'formatted_review': 'full_history_formatted_review'}, inplace=True)\n",
    "notebooks_df = notebooks_df.merge(selected_rows_df[['file_id', 'Code Quality', 'Language Quality', 'Feedback for the Trainer', 'task_link_rev']], left_on='id', right_on='file_id', how='left')\n",
    "\n",
    "notebooks_df = notebooks_df[['colab_link', 'task_link_rev', 'full_history_formatted_review', 'full_history_code_score', 'Code Quality', 'Language Quality', 'Feedback for the Trainer']]\n",
    "\n",
    "notebooks_df.rename(columns={'score': 'selected_rows_score', 'Code Quality':'Human Code Quality', 'Language Quality':'Human Language Quality', 'Feedback for the Trainer': 'Human Reviewer Feedback'}, inplace=True)\n",
    "notebooks_df['colab_link'] = notebooks_df['colab_link'].str.replace('?', '#')\n",
    "from utils import DATA_DIR\n",
    "notebooks_df.to_csv(DATA_DIR + 'full_hsitory_df_code_only.csv', index=False)\n",
    "notebooks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://colab.research.google.com/drive/1Unbsf2xICxBcqMFzYBbyS9NW4kVtr7Os\n"
     ]
    }
   ],
   "source": [
    "print(notebooks_df.loc[5]['task_link_rev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://colab.research.google.com/drive/1JUY9363HPsn5ChuweH_i31EzSsJPzSwX#revisionId=0BxmKQQ91GHhcN3ViTitrMVh2Vi82V3l6a2tpaGFWWnBLYlhZPQ\n"
     ]
    }
   ],
   "source": [
    "print(notebooks_df.loc[8]['task_link_rev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://colab.research.google.com/drive/1UeXB6ceNocGOSwSsOxH3ZQ2ZPFCBsQQn#revisionId=0BxmKQQ91GHhcV2ZiWlJKM0g4WHkwVXkzMUhuUVg1Q1hselpJPQ\n"
     ]
    }
   ],
   "source": [
    "print(notebooks_df.loc[0]['task_link_rev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Critical Severity Issues\n",
      "# Medium Severity Issues\n",
      "# Scoring Explanation\n",
      "The conversation provided does not include any code generated by the AI Assistant. The user has presented an issue with their code, and the Assistant has only asked for more information to better understand the problem. Since there is no code to evaluate, the criteria for code correctness, efficiency, best practices, readability, style consistency, and purpose cannot be applied. Therefore, the conversation cannot be scored based on the code quality rubric.\n",
      "\n",
      "# Score: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(notebooks_df.loc[8]['full_history_formatted_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1KtSOMVTE5kj8VuId-zm-y_TZVVMQwYwZ',\n",
       " 'colab_link': 'https://colab.research.google.com/drive/1KtSOMVTE5kj8VuId-zm-y_TZVVMQwYwZ',\n",
       " 'revision_id': None,\n",
       " 'metadata': {'topic': 'debugging_and_tracing', 'target_turns': '1-4'},\n",
       " 'messages': [{'role': 'User',\n",
       "   'content': \"Hi there, I'm prepping for a Smart City Planner interview. Part of my role will involve building a predictive maintenance system for urban infrastructure. Iâ€™m planning to use scikit-learn to develop the model but I'm getting stuck on fine-tuning. Any tips?\",\n",
       "   'type': 'markdown'},\n",
       "  {'role': 'Assistant',\n",
       "   'content': \"Sure thing! Fine-tuning a machine learning model can be quite nuanced. Can you tell me what kind of performance metrics you're looking at and what specifically you're seeing with your model's output? Any details on the dataset youâ€™re using will also be helpful.\",\n",
       "   'type': 'markdown'},\n",
       "  {'role': 'User',\n",
       "   'content': \"I'm using the dataset that includes historical utility data like usage patterns, failure incidents, and environmental impacts. My model's accuracy appears lower than the industry standard. Here's the basic structure Iâ€™ve been working with:\\n\\n```python\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Split the dataset\\nX_train, X_test, y_train, y_test = train_test_split(feature_data, labels, test_size=0.2)\\n\\n# Initialize the model\\nmodel = RandomForestClassifier()\\n\\n# Train the model\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions\\npredictions = model.predict(X_test)\\n\\n# Evaluate the model\\nprint(accuracy_score(y_test, predictions))\\n```\\n\\nI suspect I may need to dive deeper into hyperparameter tuning or modifying my feature set.\",\n",
       "   'type': 'markdown'},\n",
       "  {'role': 'Assistant',\n",
       "   'content': \"That's a good start. Indeed, hyperparameter tuning is essential. Considering your dataset, tuning parameters of `RandomForestClassifier` like `n_estimators`, `max_features`, and `max_depth` could lead to better results. Also, feature engineering plays a critical role in predictive maintenance; make sure to include domain-specific knowledge into your features.\\n\\nTo go about systematically, you could employ `GridSearchCV` or `RandomizedSearchCV` for hyperparameter optimization. Here's how you could incorporate cross-validation and hyperparameter tuning:\\n\\n```python\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Define the parameter grid\\nparam_grid = {\\n    'n_estimators': [100, 200, 300],\\n    'max_features': ['auto', 'sqrt', 'log2'],\\n    'max_depth': [4, 6, 8]\\n}\\n\\n# Initialize GridSearchCV\\ngrid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\\n\\n# Perform the grid search and fit the model\\ngrid_search.fit(X_train, y_train)\\n\\n# Get the best model\\nbest_model = grid_search.best_estimator_\\n\\n# Make predictions\\nbest_predictions = best_model.predict(X_test)\\n\\n# Evaluate the best model\\nprint(accuracy_score(y_test, best_predictions))\\n```\\nThis snippet begins hyperparameter tuning with `GridSearchCV`, a powerful method that evaluates all the combinations of parameters in your grid.\\n\\nIntegrating your domain expertise to prioritize which features are engineered and which hyperparameters are emphasized is advised. Does this align with your understanding of your dataset and the model's application?\",\n",
       "   'type': 'markdown'},\n",
       "  {'role': 'User',\n",
       "   'content': 'Yes, it does align well. My only concern is that GridSearchCV might be time-consuming given the exhaustive search it performs. Is there an alternative that could lead to a good-enough model but in less time?',\n",
       "   'type': 'markdown'},\n",
       "  {'role': 'Assistant',\n",
       "   'content': \"\\n**Assistant**\\n\\nYou're correct that GridSearchCV can be computationally expensive. A more time-efficient alternative is `RandomizedSearchCV`, which samples a fixed number of parameter combinations from the specified distributions. This approach can often find a good enough model much faster.\\n\\nHereâ€™s how you might set up `RandomizedSearchCV`:\\n\\n```python\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom scipy.stats import randint\\n\\n# Define the parameter distributions\\nparam_distributions = {\\n    'n_estimators': randint(100, 500),\\n    'max_features': ['auto', 'sqrt', 'log2'],\\n    'max_depth': randint(4, 10)\\n}\\n\\n# Initialize RandomizedSearchCV\\nrandom_search = RandomizedSearchCV(estimator=model,\\n                                   param_distributions=param_distributions,\\n                                   n_iter=10, cv=5, random_state=42)\\n\\n# Perform the random search and fit the model\\nrandom_search.fit(X_train, y_train)\\n\\n# Get the best model\\nbest_random_model = random_search.best_estimator_\\n\\n# Make predictions\\nbest_random_predictions = best_random_model.predict(X_test)\\n\\n# Evaluate the best random model\\nprint(accuracy_score(y_test, best_random_predictions))\\n```\\n\\nThis code will try out ten different combinations from your distribution and pick the best one, striking a balance between performance and time. How does this methodology fit into your workflow?\",\n",
       "   'type': 'markdown'},\n",
       "  {'role': 'User',\n",
       "   'content': 'That seems like a practical approach to get me started. However, once I find a promising model configuration, is there a way to refine it further?',\n",
       "   'type': 'markdown'},\n",
       "  {'role': 'Assistant',\n",
       "   'content': \"Certainly! Once you've narrowed down the hyperparameter space using `RandomizedSearchCV`, you can hone in on the best parameters by running a more focused `GridSearchCV` around those values. Here's what you can do:\\n\\n```python\\n# Assume these are the promising ranges found from RandomizedSearchCV\\nn_estimators_range = [best_random_model.n_estimators - 50, best_random_model.n_estimators, best_random_model.n_estimators + 50]\\nmax_depth_range = [best_random_model.max_depth - 2, best_random_model.max_depth, best_random_model.max_depth + 2]\\nmax_features_range = [best_random_model.max_features]\\n\\n# Define a new grid based on the output of RandomizedSearchCV\\nrefined_param_grid = {\\n    'n_estimators': n_estimators_range,\\n    'max_features': max_features_range,\\n    'max_depth': max_depth_range\\n}\\n\\n# Initialize a new GridSearchCV with the refined grid\\nrefined_grid_search = GridSearchCV(estimator=model, param_grid=refined_param_grid, cv=5)\\n\\n# Perform the grid search and fit the model\\nrefined_grid_search.fit(X_train, y_train)\\n\\n# Get the best refined model\\nbest_refined_model = refined_grid_search.best_estimator_\\n\\n# Make predictions\\nrefined_predictions = best_refined_model.predict(X_test)\\n\\n# Evaluate the best refined model\\nprint(accuracy_score(y_test, refined_predictions))\\n```\\n\\nBy iterating between randomized and grid searches, you can efficiently narrow your hyperparameter search space and then conduct a thorough exploration within that refined range. This two-step approach allows you to be thorough yet efficient with your timeâ€”a perfect discussion point for your interview.\",\n",
       "   'type': 'markdown'}],\n",
       " 'raw_review': {'critical_severity_issues': [],\n",
       "  'medium_severity_issues': [{'cell_position': 4,\n",
       "    'what': 'The code snippet does not handle the case where `feature_data` and `labels` are undefined.',\n",
       "    'why': \"The code assumes that `feature_data` and `labels` are predefined variables without ensuring their existence or loading them from a data source, which could lead to a `NameError` if they are not defined in the user's environment.\",\n",
       "    'where': 'In the code snippet where `train_test_split(feature_data, labels, test_size=0.2)` is called.',\n",
       "    'fix': 'Include code to load the dataset or check if `feature_data` and `labels` are defined before using them.'},\n",
       "   {'cell_position': 6,\n",
       "    'what': 'The code snippet uses a fixed `random_state` without explanation.',\n",
       "    'why': 'Setting a `random_state` ensures reproducibility but the choice of the number should be justified or at least mentioned to the user.',\n",
       "    'where': 'In the `RandomizedSearchCV` initialization: `random_state=42`.',\n",
       "    'fix': 'Explain the purpose of setting a `random_state` and why the number 42 was chosen, or allow the user to set their own `random_state`.'}],\n",
       "  'could_have_been_better_issues': [{'cell_position': 4,\n",
       "    'what': 'The code snippet does not include an import statement for `RandomForestClassifier`.',\n",
       "    'why': \"While the user provided a code snippet with the import statement, the Assistant's code snippet should be self-contained and include all necessary imports for clarity.\",\n",
       "    'where': 'In the code snippet provided for hyperparameter tuning with `GridSearchCV`.',\n",
       "    'fix': 'Add the line `from sklearn.ensemble import RandomForestClassifier` at the beginning of the code snippet.'},\n",
       "   {'cell_position': 8,\n",
       "    'what': 'The code snippet assumes the existence of `best_random_model` without showing how it is obtained.',\n",
       "    'why': 'The code snippet uses `best_random_model` to define the ranges for the refined grid search, but it does not show the previous step of obtaining this model from `RandomizedSearchCV`, which might confuse the user.',\n",
       "    'where': 'In the code snippet where `n_estimators_range`, `max_depth_range`, and `max_features_range` are defined based on `best_random_model`.',\n",
       "    'fix': 'Include a comment or a brief explanation that `best_random_model` is the result of the previous `RandomizedSearchCV` step.'}],\n",
       "  'scoring_explanation': \"The code provided by the Assistant is correct and follows best practices for hyperparameter tuning using `GridSearchCV` and `RandomizedSearchCV`. The code is readable and consistent with the Assistant's programming identity. However, there are medium severity issues related to the assumptions of predefined variables and the use of a fixed `random_state`. These issues could lead to errors if the user's environment is not set up as expected by the Assistant's code. Additionally, there are minor issues with the code snippets not being entirely self-contained and lacking some context, which could be improved for better clarity. The conversation is complete, and the user's request for understanding hyperparameter tuning alternatives and further refinement is satisfied.\",\n",
       "  'score': 4},\n",
       " 'formatted_review': \"# Critical Severity Issues\\n# Medium Severity Issues\\n**Cell 4**: The code snippet does not handle the case where `feature_data` and `labels` are undefined.\\n- **Why**: The code assumes that `feature_data` and `labels` are predefined variables without ensuring their existence or loading them from a data source, which could lead to a `NameError` if they are not defined in the user's environment.\\n- **Where**: In the code snippet where `train_test_split(feature_data, labels, test_size=0.2)` is called.\\n- **Fix**: Include code to load the dataset or check if `feature_data` and `labels` are defined before using them.\\n\\n**Cell 6**: The code snippet uses a fixed `random_state` without explanation.\\n- **Why**: Setting a `random_state` ensures reproducibility but the choice of the number should be justified or at least mentioned to the user.\\n- **Where**: In the `RandomizedSearchCV` initialization: `random_state=42`.\\n- **Fix**: Explain the purpose of setting a `random_state` and why the number 42 was chosen, or allow the user to set their own `random_state`.\\n\\n# Scoring Explanation\\nThe code provided by the Assistant is correct and follows best practices for hyperparameter tuning using `GridSearchCV` and `RandomizedSearchCV`. The code is readable and consistent with the Assistant's programming identity. However, there are medium severity issues related to the assumptions of predefined variables and the use of a fixed `random_state`. These issues could lead to errors if the user's environment is not set up as expected by the Assistant's code. Additionally, there are minor issues with the code snippets not being entirely self-contained and lacking some context, which could be improved for better clarity. The conversation is complete, and the user's request for understanding hyperparameter tuning alternatives and further refinement is satisfied.\\n\\n# Score: 4\\n\\n\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_notebooks[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_link</th>\n",
       "      <th>full_history_formatted_review</th>\n",
       "      <th>full_history_code_score</th>\n",
       "      <th>Human Code Quality</th>\n",
       "      <th>Human Language Quality</th>\n",
       "      <th>Human Reviewer Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1UeXB6...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>- missing code example in first turn, a sample...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1qJPPq...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>--It's empty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1cP6qz...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-- No Explanation\\n-- No Headers\\n-- No Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1CPEz-...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/189Fne...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://colab.research.google.com/drive/1Unbsf...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://colab.research.google.com/drive/1KtSOM...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://colab.research.google.com/drive/1_lUJ5...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-- assistant header is wrong it should be **As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://colab.research.google.com/drive/1JUY93...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-- really low effort, I understand that someti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://colab.research.google.com/drive/1kL_7R...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-- The user question is clearly a copy and pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://colab.research.google.com/drive/1FIo_t...</td>\n",
       "      <td># Critical Severity Issues\\n**Cell 2**: Incorr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>- Requirement was 4-8 turns only found 1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://colab.research.google.com/drive/182Eqz...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>--Assistant does not have access to links \\nRa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://colab.research.google.com/drive/1yfP7u...</td>\n",
       "      <td># Critical Severity Issues\\n# Medium Severity ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-- the code is incorrect. I think you copied t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           colab_link  \\\n",
       "0   https://colab.research.google.com/drive/1UeXB6...   \n",
       "1   https://colab.research.google.com/drive/1qJPPq...   \n",
       "2   https://colab.research.google.com/drive/1cP6qz...   \n",
       "3   https://colab.research.google.com/drive/1CPEz-...   \n",
       "4   https://colab.research.google.com/drive/189Fne...   \n",
       "5   https://colab.research.google.com/drive/1Unbsf...   \n",
       "6   https://colab.research.google.com/drive/1KtSOM...   \n",
       "7   https://colab.research.google.com/drive/1_lUJ5...   \n",
       "8   https://colab.research.google.com/drive/1JUY93...   \n",
       "9   https://colab.research.google.com/drive/1kL_7R...   \n",
       "10  https://colab.research.google.com/drive/1FIo_t...   \n",
       "11  https://colab.research.google.com/drive/182Eqz...   \n",
       "12  https://colab.research.google.com/drive/1yfP7u...   \n",
       "\n",
       "                        full_history_formatted_review  \\\n",
       "0   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "1   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "2   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "3   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "4   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "5   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "6   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "7   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "8   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "9   # Critical Severity Issues\\n# Medium Severity ...   \n",
       "10  # Critical Severity Issues\\n**Cell 2**: Incorr...   \n",
       "11  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "12  # Critical Severity Issues\\n# Medium Severity ...   \n",
       "\n",
       "    full_history_code_score Human Code Quality Human Language Quality  \\\n",
       "0                         3                  3                      3   \n",
       "1                         5                  1                      1   \n",
       "2                         3                  2                      1   \n",
       "3                         4                NaN                    NaN   \n",
       "4                         3                NaN                    NaN   \n",
       "5                         4                NaN                    NaN   \n",
       "6                         3                NaN                    NaN   \n",
       "7                         5                  1                      1   \n",
       "8                         5                  2                      2   \n",
       "9                         5                  1                      1   \n",
       "10                        2                  1                      1   \n",
       "11                        5                  2                      2   \n",
       "12                        3                  2                      5   \n",
       "\n",
       "                              Human Reviewer Feedback  \n",
       "0   - missing code example in first turn, a sample...  \n",
       "1                                       --It's empty.  \n",
       "2    -- No Explanation\\n-- No Headers\\n-- No Comments  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7   -- assistant header is wrong it should be **As...  \n",
       "8   -- really low effort, I understand that someti...  \n",
       "9   -- The user question is clearly a copy and pas...  \n",
       "10          - Requirement was 4-8 turns only found 1.  \n",
       "11  --Assistant does not have access to links \\nRa...  \n",
       "12  -- the code is incorrect. I think you copied t...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "notebooks_df = pd.DataFrame(parsed_notebooks)\n",
    "notebooks_df['full_history_code_score'] = notebooks_df['raw_review'].apply(lambda x: x.get('score') if x is not None else None)\n",
    "notebooks_df.rename(columns={'formatted_review': 'full_history_formatted_review'}, inplace=True)\n",
    "notebooks_df = notebooks_df.merge(selected_rows_df[['file_id', 'Code Quality', 'Language Quality', 'Feedback for the Trainer']], left_on='id', right_on='file_id', how='left')\n",
    "\n",
    "notebooks_df = notebooks_df[['colab_link', 'full_history_formatted_review', 'full_history_code_score', 'Code Quality', 'Language Quality', 'Feedback for the Trainer']]\n",
    "\n",
    "notebooks_df.rename(columns={'score': 'selected_rows_score', 'Code Quality':'Human Code Quality', 'Language Quality':'Human Language Quality', 'Feedback for the Trainer': 'Human Reviewer Feedback'}, inplace=True)\n",
    "notebooks_df['colab_link'] = notebooks_df['colab_link'].str.replace('?', '#')\n",
    "from utils import DATA_DIR\n",
    "notebooks_df.to_csv(DATA_DIR + 'full_hsitory_df_code_only.csv', index=False)\n",
    "notebooks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
